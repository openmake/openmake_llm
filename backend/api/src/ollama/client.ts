import axios, { AxiosInstance } from 'axios';
import {
    OllamaConfig,
    GenerateRequest,
    GenerateResponse,
    ChatRequest,
    ChatResponse,
    ChatMessage,
    ListModelsResponse,
    ModelOptions,
    ThinkOption,
    FormatOption,
    ToolDefinition,
    ToolCall,
    EmbedRequest,
    EmbedResponse,
    UsageMetrics,
    WebSearchRequest,
    WebSearchResponse,
    WebFetchRequest,
    WebFetchResponse
} from './types';
import { getConfig } from '../config';
import { createLogger } from '../utils/logger';
import { getApiKeyManager, ApiKeyManager } from './api-key-manager';
import { getApiUsageTracker } from './api-usage-tracker';
import { QuotaExceededError } from '../errors/quota-exceeded.error';
import { runAgentLoop, AgentLoopOptions, AgentLoopResult } from './agent-loop';

const logger = createLogger('OllamaClient');

const envConfig = getConfig();

const DEFAULT_CONFIG: OllamaConfig = {
    baseUrl: envConfig.ollamaBaseUrl,
    model: envConfig.ollamaDefaultModel,
    timeout: envConfig.ollamaTimeout
};

export class OllamaClient {
    private client: AxiosInstance;
    private config: OllamaConfig;
    private context: number[] = [];
    private apiKeyManager: ApiKeyManager;

    // ğŸ†• Ollama Cloud í˜¸ìŠ¤íŠ¸ ìƒìˆ˜
    private static readonly OLLAMA_CLOUD_HOST = 'https://ollama.com';

    constructor(config: Partial<OllamaConfig> = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.apiKeyManager = getApiKeyManager();

        // ğŸ†• ëª¨ë¸ì´ :cloud ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§€ë©´ Ollama Cloud í˜¸ìŠ¤íŠ¸ ì‚¬ìš©
        let baseUrl = this.config.baseUrl;
        if (this.isCloudModel(this.config.model)) {
            baseUrl = OllamaClient.OLLAMA_CLOUD_HOST;
            console.log(`[OllamaClient] ğŸŒ Cloud ëª¨ë¸ ê°ì§€ - í˜¸ìŠ¤íŠ¸: ${baseUrl}`);
        }

        this.client = axios.create({
            baseURL: baseUrl,
            timeout: this.config.timeout,
            headers: {
                'Content-Type': 'application/json',
                ...this.apiKeyManager.getAuthHeaders()
            }
        });

        // ğŸ†• ìš”ì²­ ì¸í„°ì…‰í„°: ë™ì  API í‚¤ ì£¼ì…
        this.client.interceptors.request.use((config) => {
            const authHeaders = this.apiKeyManager.getAuthHeaders();
            if (authHeaders.Authorization) {
                config.headers.Authorization = authHeaders.Authorization;
            }
            return config;
        });

        // ğŸ†• ì‘ë‹µ ì¸í„°ì…‰í„°: ì‹¤íŒ¨ ì‹œ í´ë°± ì²˜ë¦¬ (ëª¨ë“  API í‚¤ ìˆœí™˜ ì‹œë„)
        this.client.interceptors.response.use(
            (response) => {
                this.apiKeyManager.reportSuccess();
                return response;
            },
            async (error) => {
                const statusCode = error?.response?.status;
                console.log(`[OllamaClient] âŒ ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ: ${statusCode}`);

                // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ (ETIMEDOUT, ECONNREFUSED ë“±) ì‹œ ì¬ì‹œë„
                const isNetworkError = !statusCode && (
                    error.code === 'ETIMEDOUT' ||
                    error.code === 'ECONNREFUSED' ||
                    error.code === 'ECONNRESET' ||
                    error.code === 'ENOTFOUND' ||
                    error.code === 'EAI_AGAIN'
                );

                // 429, 401, 403 ì—ëŸ¬ ì‹œ API í‚¤ ìŠ¤ì™€í•‘ ì‹œë„
                if (statusCode === 429 || statusCode === 401 || statusCode === 403) {
                    // ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì  (í‚¤ ê°œìˆ˜ë§Œí¼ ì‹œë„)
                    const retryCount = error.config?._retryCount || 0;
                    const maxRetries = this.apiKeyManager.getTotalKeys() - 1;

                    console.log(`[OllamaClient] ğŸ”„ API í‚¤ ìŠ¤ì™€í•‘ ì‹œë„ ì¤‘... (${retryCount + 1}/${maxRetries + 1})`);
                    const switched = this.apiKeyManager.reportFailure(error);

                    if (switched && error.config && retryCount < maxRetries) {
                        error.config._retryCount = retryCount + 1;
                        const newAuthHeaders = this.apiKeyManager.getAuthHeaders();
                        error.config.headers.Authorization = newAuthHeaders.Authorization;
                        console.log(`[OllamaClient] âœ… ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„ (Key ${this.apiKeyManager.getCurrentKeyIndex() + 1})...`);
                        return this.client.request(error.config);
                    } else {
                        console.log(`[OllamaClient] âš ï¸ ëª¨ë“  í‚¤ ì†Œì§„ - switched: ${switched}, retryCount: ${retryCount}/${maxRetries}`);
                    }
                } else if (isNetworkError && error.config) {
                    // ë„¤íŠ¸ì›Œí¬ ì¼ì‹œ ì¥ì•  ì‹œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
                    const retryCount = error.config._retryCount || 0;
                    const maxNetworkRetries = 2;
                    if (retryCount < maxNetworkRetries) {
                        error.config._retryCount = retryCount + 1;
                        const backoffMs = Math.pow(2, retryCount) * 1000; // 1s, 2s
                        console.log(`[OllamaClient] ğŸ”„ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬(${error.code}) - ${backoffMs}ms í›„ ì¬ì‹œë„ (${retryCount + 1}/${maxNetworkRetries})`);
                        await new Promise(resolve => setTimeout(resolve, backoffMs));
                        return this.client.request(error.config);
                    }
                    console.log(`[OllamaClient] âš ï¸ ë„¤íŠ¸ì›Œí¬ ì¬ì‹œë„ ì†Œì§„ (${error.code})`);
                    this.apiKeyManager.reportFailure(error);
                } else {
                    this.apiKeyManager.reportFailure(error);
                }

                throw error;
            }
        );
    }

    get model(): string {
        return this.config.model;
    }

    /**
     * ğŸ†• ëª¨ë¸ì´ Cloud ëª¨ë¸(:cloud ì ‘ë¯¸ì‚¬)ì¸ì§€ í™•ì¸
     */
    private isCloudModel(model: string): boolean {
        return model?.toLowerCase().endsWith(':cloud') ?? false;
    }

    setModel(model: string): void {
        this.config.model = model;
    }

    async listModels(): Promise<ListModelsResponse> {
        const response = await this.client.get<ListModelsResponse>('/api/tags');
        return response.data;
    }


    /**
     * Check API quota before making a request.
     * Throws QuotaExceededError if hourly or weekly limit is exceeded.
     */
    private checkQuota(): void {
        try {
            const tracker = getApiUsageTracker();
            const quota = tracker.getQuotaStatus();

            if (quota.hourly.remaining <= 0 && quota.weekly.remaining <= 0) {
                throw new QuotaExceededError('both', quota.weekly.used, quota.weekly.limit);
            }
            if (quota.hourly.remaining <= 0) {
                throw new QuotaExceededError('hourly', quota.hourly.used, quota.hourly.limit);
            }
            if (quota.weekly.remaining <= 0) {
                throw new QuotaExceededError('weekly', quota.weekly.used, quota.weekly.limit);
            }
        } catch (error) {
            // Re-throw QuotaExceededError, ignore other errors (tracker init failures)
            if (error instanceof QuotaExceededError) {
                throw error;
            }
            logger.warn('Quota check failed (non-blocking):', error);
        }
    }

    async generate(
        prompt: string,
        options?: ModelOptions,
        onToken?: (token: string) => void,
        images?: string[]
    ): Promise<{ response: string; metrics?: UsageMetrics }> {
        this.checkQuota();

        const request: GenerateRequest = {
            model: this.config.model,
            prompt,
            context: this.context,
            stream: !!onToken,
            options,
            images
        };

        if (onToken) {
            return this.streamGenerate(request, onToken);
        }

        const response = await this.client.post<GenerateResponse>('/api/generate', request);
        this.context = response.data.context || [];
        return {
            response: response.data.response,
            metrics: {
                total_duration: response.data.total_duration,
                load_duration: response.data.load_duration,
                prompt_eval_count: response.data.prompt_eval_count,
                prompt_eval_duration: response.data.prompt_eval_duration,
                eval_count: response.data.eval_count,
                eval_duration: response.data.eval_duration
            }
        };
    }

    private async streamGenerate(
        request: GenerateRequest,
        onToken: (token: string) => void
    ): Promise<{ response: string; metrics?: UsageMetrics }> {
        const response = await this.client.post('/api/generate', request, {
            responseType: 'stream'
        });

        let fullResponse = '';
        let metrics: UsageMetrics | undefined;

        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const data: GenerateResponse = JSON.parse(line);
                            if (data.response) {
                                fullResponse += data.response;
                                onToken(data.response);
                            }
                            if (data.done) {
                                if (data.context) {
                                    this.context = data.context;
                                }
                                metrics = {
                                    total_duration: data.total_duration,
                                    load_duration: data.load_duration,
                                    prompt_eval_count: data.prompt_eval_count,
                                    prompt_eval_duration: data.prompt_eval_duration,
                                    eval_count: data.eval_count,
                                    eval_duration: data.eval_duration
                                };
                            }
                        } catch (e) {
                            console.error('[OllamaClient] JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const data: GenerateResponse = JSON.parse(buffer);
                        if (data.response) {
                            fullResponse += data.response;
                            onToken(data.response);
                        }
                        if (data.done) {
                            metrics = {
                                total_duration: data.total_duration,
                                load_duration: data.load_duration,
                                prompt_eval_count: data.prompt_eval_count,
                                prompt_eval_duration: data.prompt_eval_duration,
                                eval_count: data.eval_count,
                                eval_duration: data.eval_duration
                            };
                        }
                    } catch (e) { /* ignore */ }
                }
                resolve({ response: fullResponse, metrics });
            });
            response.data.on('error', reject);
        });
    }

    /**
     * Enhanced chat with Thinking, Structured Outputs, and Tool Calling support
     */
    async chat(
        messages: ChatMessage[],
        options?: ModelOptions,
        onToken?: (token: string, thinking?: string) => void,
        advancedOptions?: {
            think?: ThinkOption;
            format?: FormatOption;
            tools?: ToolDefinition[];
        }
    ): Promise<ChatMessage & { metrics?: UsageMetrics }> {
        this.checkQuota();

        const request: ChatRequest = {
            model: this.config.model,
            messages,
            stream: !!onToken,
            options,
            ...(advancedOptions?.think !== undefined && { think: advancedOptions.think }),
            ...(advancedOptions?.format && { format: advancedOptions.format }),
            ...(advancedOptions?.tools && { tools: advancedOptions.tools })
        };

        if (onToken) {
            return this.streamChat(request, onToken);
        }

        const response = await this.client.post<ChatResponse>('/api/chat', request);
        return {
            ...response.data.message,
            metrics: {
                total_duration: response.data.total_duration,
                load_duration: response.data.load_duration,
                prompt_eval_count: response.data.prompt_eval_count,
                prompt_eval_duration: response.data.prompt_eval_duration,
                eval_count: response.data.eval_count,
                eval_duration: response.data.eval_duration
            }
        };
    }

    private async streamChat(
        request: ChatRequest,
        onToken: (token: string, thinking?: string) => void
    ): Promise<ChatMessage & { metrics?: UsageMetrics }> {
        const response = await this.client.post('/api/chat', request, {
            responseType: 'stream'
        });

        let fullContent = '';
        let fullThinking = '';
        let toolCalls: ToolCall[] = [];
        let metrics: UsageMetrics | undefined;

        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                // logger.debug(`Data chunk received: ${chunk.length} bytes`); // Log noise reduction
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const data: ChatResponse = JSON.parse(line);

                            // Handle thinking trace
                            if (data.message?.thinking) {
                                fullThinking += data.message.thinking;
                                onToken('', data.message.thinking);
                            }

                            // Handle content
                            if (data.message?.content) {
                                fullContent += data.message.content;
                                onToken(data.message.content);
                            }

                            // Handle tool calls
                            if (data.message?.tool_calls) {
                                toolCalls = data.message.tool_calls;
                            }

                            if (data.done) {
                                metrics = {
                                    total_duration: data.total_duration,
                                    load_duration: data.load_duration,
                                    prompt_eval_count: data.prompt_eval_count,
                                    prompt_eval_duration: data.prompt_eval_duration,
                                    eval_count: data.eval_count,
                                    eval_duration: data.eval_duration
                                };
                            }
                        } catch (e) {
                            console.error('[OllamaClient] Chat JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const data: ChatResponse = JSON.parse(buffer);
                        if (data.message?.thinking) fullThinking += data.message.thinking;
                        if (data.message?.content) {
                            fullContent += data.message.content;
                            onToken(data.message.content);
                        }
                        if (data.message?.tool_calls) toolCalls = data.message.tool_calls;
                        if (data.done) {
                            metrics = {
                                total_duration: data.total_duration,
                                load_duration: data.load_duration,
                                prompt_eval_count: data.prompt_eval_count,
                                prompt_eval_duration: data.prompt_eval_duration,
                                eval_count: data.eval_count,
                                eval_duration: data.eval_duration
                            };
                        }
                    } catch (e) { /* ignore */ }
                }

                const result: ChatMessage & { metrics?: UsageMetrics } = {
                    role: 'assistant',
                    content: fullContent,
                    metrics
                };

                if (fullThinking) {
                    result.thinking = fullThinking;
                }

                if (toolCalls.length > 0) {
                    result.tool_calls = toolCalls;
                }

                resolve(result);
            });
            response.data.on('error', reject);
        });
    }

    /**
     * Generate embeddings for text (Ollama Embeddings API)
     */
    async embed(input: string | string[], model?: string): Promise<number[][]> {
        const request: EmbedRequest = {
            model: model || 'embeddinggemma',
            input
        };

        const response = await this.client.post<EmbedResponse>('/api/embed', request);
        return response.data.embeddings;
    }

    async isAvailable(): Promise<boolean> {
        try {
            await this.client.get('/');
            return true;
        } catch {
            return false;
        }
    }

    clearContext(): void {
        this.context = [];
    }

    // ============================================
    // Ollama Web Search API Methods
    // ============================================

    /**
     * Ollama ê³µì‹ Web Search API
     * https://ollama.com/api/web_search
     */
    async webSearch(query: string, maxResults: number = 5): Promise<WebSearchResponse> {
        const request: WebSearchRequest = {
            query,
            max_results: Math.min(maxResults, 10)
        };

        console.log(`[OllamaClient] ğŸ” Web Search: "${query}"`);

        try {
            // Ollama ê³µì‹ API ì—”ë“œí¬ì¸íŠ¸
            const response = await this.client.post<WebSearchResponse>(
                'https://ollama.com/api/web_search',
                request,
                {
                    baseURL: '', // Override baseURL to use absolute URL
                    headers: {
                        'Content-Type': 'application/json',
                        ...this.apiKeyManager.getAuthHeaders()
                    }
                }
            );

            console.log(`[OllamaClient] âœ… Web Search: ${response.data.results?.length || 0}ê°œ ê²°ê³¼`);
            return response.data;
        } catch (error: unknown) {
            console.error('[OllamaClient] Web Search ì‹¤íŒ¨:', (error instanceof Error ? error.message : String(error)));
            return { results: [] };
        }
    }

    /**
     * Ollama ê³µì‹ Web Fetch API
     * https://ollama.com/api/web_fetch
     */
    async webFetch(url: string): Promise<WebFetchResponse> {
        const request: WebFetchRequest = { url };

        console.log(`[OllamaClient] ğŸ“¥ Web Fetch: ${url}`);

        try {
            const response = await this.client.post<WebFetchResponse>(
                'https://ollama.com/api/web_fetch',
                request,
                {
                    baseURL: '',
                    headers: {
                        'Content-Type': 'application/json',
                        ...this.apiKeyManager.getAuthHeaders()
                    }
                }
            );

            console.log(`[OllamaClient] âœ… Web Fetch: "${response.data.title}"`);
            return response.data;
        } catch (error: unknown) {
            console.error('[OllamaClient] Web Fetch ì‹¤íŒ¨:', (error instanceof Error ? error.message : String(error)));
            return { title: '', content: '', links: [] };
        }
    }

    // ============================================
    // Multi-turn Tool Calling (Agent Loop)
    // ============================================

    /**
     * Multi-turn Tool Calling Agent Loop ì‹¤í–‰
     * 
     * ë„êµ¬ í˜¸ì¶œì´ ì—†ì„ ë•Œê¹Œì§€ ìë™ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.
     * ê³µì‹ ë¬¸ì„œ: https://docs.ollama.com/capabilities/tool-calling#multi-turn-tool-calling-agent-loop
     * 
     * @example
     * ```typescript
     * const result = await client.runAgentLoop(
     *   [{ role: 'user', content: 'ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜' }],
     *   [weatherTool],
     *   { get_weather: getWeatherFunc },
     *   { onToolCall: (name, args, result) => console.log(`Tool: ${name}`) }
     * );
     * ```
     */
    async runAgentLoop(
        messages: ChatMessage[],
        tools: ToolDefinition[],
        availableFunctions: Record<string, (args: Record<string, unknown>) => unknown | Promise<unknown>>,
        options?: {
            think?: ThinkOption;
            stream?: boolean;
            onToken?: (token: string, thinking?: string) => void;
            onToolCall?: (name: string, args: unknown, result: unknown) => void;
            maxIterations?: number;
        }
    ): Promise<AgentLoopResult> {
        return runAgentLoop({
            model: this.config.model,
            messages,
            tools,
            availableFunctions,
            think: options?.think,
            stream: options?.stream,
            onToken: options?.onToken,
            onToolCall: options?.onToolCall,
            maxIterations: options?.maxIterations
        });
    }
}

export const createClient = (config?: Partial<OllamaConfig>): OllamaClient => {
    return new OllamaClient(config);
};
