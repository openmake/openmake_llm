/**
 * ============================================================
 * OllamaClient - Ollama HTTP í´ë¼ì´ì–¸íŠ¸
 * ============================================================
 *
 * Ollama APIì™€ì˜ HTTP í†µì‹ ì„ ë‹´ë‹¹í•˜ëŠ” í•µì‹¬ í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆì…ë‹ˆë‹¤.
 * Cloud/Local ëª¨ë¸ ìë™ ê°ì§€, API Key ìë™ ë¡œí…Œì´ì…˜, ìŠ¤íŠ¸ë¦¬ë° ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤.
 *
 * @module ollama/client
 * @description
 * - Generate/Chat/Embed API í˜¸ì¶œ (ìŠ¤íŠ¸ë¦¬ë° ë° ë¹„ìŠ¤íŠ¸ë¦¬ë°)
 * - Cloud ëª¨ë¸(:cloud ì ‘ë¯¸ì‚¬) ìë™ ê°ì§€ ë° í˜¸ìŠ¤íŠ¸ ì „í™˜
 * - Axios ì¸í„°ì…‰í„°ë¥¼ í†µí•œ API Key ë™ì  ì£¼ì… ë° ìë™ ë¡œí…Œì´ì…˜
 * - 429/401/403 ì—ëŸ¬ ì‹œ ìë™ í‚¤ ìŠ¤ì™€í•‘, ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„
 * - ì‚¬ìš©ëŸ‰ ì¿¼í„° ê²€ì‚¬ (QuotaExceededError)
 * - Web Search/Fetch API, Agent Loop ìœ„ì„
 * - A2A ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì¸ë±ìŠ¤ ê¸°ë°˜ í´ë¼ì´ì–¸íŠ¸ íŒ©í† ë¦¬
 *
 * @requires axios - HTTP í´ë¼ì´ì–¸íŠ¸
 * @requires ./api-key-manager - API Key ë¡œí…Œì´ì…˜ ê´€ë¦¬
 * @requires ./api-usage-tracker - ì‚¬ìš©ëŸ‰ ì¶”ì /ì¿¼í„° ê´€ë¦¬
 */
import axios, { AxiosInstance } from 'axios';
import {
    OllamaConfig,
    GenerateRequest,
    GenerateResponse,
    ChatRequest,
    ChatResponse,
    ChatMessage,
    ListModelsResponse,
    ModelOptions,
    ThinkOption,
    FormatOption,
    ToolDefinition,
    ToolCall,
    EmbedRequest,
    EmbedResponse,
    UsageMetrics,
    WebSearchRequest,
    WebSearchResponse,
    WebFetchRequest,
    WebFetchResponse,
    ShowModelRequest,
    ShowModelResponse,
    PsResponse
} from './types';
import { getConfig } from '../config';
import { OLLAMA_CLOUD_HOST } from '../config/constants';
import { createLogger } from '../utils/logger';
import { getApiKeyManager, ApiKeyManager } from './api-key-manager';
import { getApiUsageTracker } from './api-usage-tracker';
import { QuotaExceededError } from '../errors/quota-exceeded.error';
import { KeyExhaustionError } from '../errors/key-exhaustion.error';
import { runAgentLoop, AgentLoopResult } from './agent-loop';

const logger = createLogger('OllamaClient');

const envConfig = getConfig();

const DEFAULT_CONFIG: OllamaConfig = {
    baseUrl: envConfig.ollamaBaseUrl,
    model: envConfig.ollamaDefaultModel,
    timeout: envConfig.ollamaTimeout
};

/**
 * Ollama HTTP í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
 *
 * Ollama API(ë¡œì»¬/í´ë¼ìš°ë“œ)ì™€ì˜ ëª¨ë“  HTTP í†µì‹ ì„ ê´€ë¦¬í•©ë‹ˆë‹¤.
 * Axios ì¸í„°ì…‰í„°ë¥¼ í†µí•´ API Key ìë™ ì£¼ì…/ë¡œí…Œì´ì…˜ì„ ì²˜ë¦¬í•˜ë©°,
 * ìŠ¤íŠ¸ë¦¬ë°/ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œì˜ Generate/Chat/Embed APIë¥¼ ì§€ì›í•©ë‹ˆë‹¤.
 *
 * @class OllamaClient
 *
 * @example
 * ```typescript
 * const client = new OllamaClient({ model: 'gemini-3-flash-preview:cloud' });
 * const result = await client.chat(
 *   [{ role: 'user', content: 'ì•ˆë…•í•˜ì„¸ìš”' }],
 *   undefined,
 *   (token) => process.stdout.write(token)
 * );
 * ```
 */
export class OllamaClient {
    /** Axios HTTP í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ (ì¸í„°ì…‰í„° í¬í•¨) */
    private client: AxiosInstance;
    /** Ollama í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (baseUrl, model, timeout) */
    private config: OllamaConfig;
    /** ì—°ì† ëŒ€í™”ë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ í† í° ë°°ì—´ (Generate APIìš©) */
    private context: number[] = [];
    /** API Key ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤ (í‚¤ ë¡œí…Œì´ì…˜ ë‹´ë‹¹) */
    private apiKeyManager: ApiKeyManager;

    // ğŸ†• Ollama Cloud í˜¸ìŠ¤íŠ¸ ìƒìˆ˜ (constants.tsì—ì„œ ì¤‘ì•™ ê´€ë¦¬)

    /**
     * OllamaClient ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     *
     * ì´ˆê¸°í™” ì‹œ ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
     * 1. Cloud ëª¨ë¸(:cloud ì ‘ë¯¸ì‚¬) ê°ì§€ ì‹œ baseUrlì„ Ollama Cloud í˜¸ìŠ¤íŠ¸ë¡œ ì „í™˜
     * 2. Axios ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ê¸°ë³¸ í—¤ë” ì„¤ì •
     * 3. ìš”ì²­ ì¸í„°ì…‰í„°: ë§¤ ìš”ì²­ë§ˆë‹¤ í˜„ì¬ í™œì„± API Keyë¥¼ Authorization í—¤ë”ì— ë™ì  ì£¼ì…
     * 4. ì‘ë‹µ ì¸í„°ì…‰í„°: 429/401/403 ì—ëŸ¬ ì‹œ API Key ìë™ ìŠ¤ì™€í•‘ í›„ ì¬ì‹œë„,
     *    ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬(ETIMEDOUT ë“±) ì‹œ ì§€ìˆ˜ ë°±ì˜¤í”„(1s, 2s)ë¡œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„,
     *    ëª¨ë“  í‚¤ ì†Œì§„ ì‹œ KeyExhaustionError throw
     *
     * @param config - Ollama í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë¶€ë¶„ ì ìš© ê°€ëŠ¥, ë¯¸ì§€ì • ì‹œ í™˜ê²½ë³€ìˆ˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
     * @throws {KeyExhaustionError} ëª¨ë“  API í‚¤ê°€ ì†Œì§„ë˜ì–´ ìš”ì²­ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°
     */
    constructor(config: Partial<OllamaConfig> = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.apiKeyManager = getApiKeyManager();

        // ğŸ†• ëª¨ë¸ì´ :cloud ì ‘ë¯¸ì‚¬ë¥¼ ê°€ì§€ë©´ Ollama Cloud í˜¸ìŠ¤íŠ¸ ì‚¬ìš©
        let baseUrl = this.config.baseUrl;
        if (this.isCloudModel(this.config.model)) {
            baseUrl = OLLAMA_CLOUD_HOST;
            console.log(`[OllamaClient] ğŸŒ Cloud ëª¨ë¸ ê°ì§€ - í˜¸ìŠ¤íŠ¸: ${baseUrl}`);
        }

        this.client = axios.create({
            baseURL: baseUrl,
            timeout: this.config.timeout,
            headers: {
                'Content-Type': 'application/json',
                ...this.apiKeyManager.getAuthHeaders()
            }
        });

        // ğŸ†• ìš”ì²­ ì¸í„°ì…‰í„°: ë™ì  API í‚¤ ì£¼ì…
        this.client.interceptors.request.use((config) => {
            const authHeaders = this.apiKeyManager.getAuthHeaders();
            if (authHeaders.Authorization) {
                config.headers.Authorization = authHeaders.Authorization;
            }
            return config;
        });

        // ğŸ†• ì‘ë‹µ ì¸í„°ì…‰í„°: ì‹¤íŒ¨ ì‹œ í´ë°± ì²˜ë¦¬ (ëª¨ë“  API í‚¤ ìˆœí™˜ ì‹œë„)
        this.client.interceptors.response.use(
            (response) => {
                this.apiKeyManager.reportSuccess();
                return response;
            },
            async (error) => {
                const statusCode = error?.response?.status;
                console.log(`[OllamaClient] âŒ ìš”ì²­ ì‹¤íŒ¨ - ìƒíƒœ ì½”ë“œ: ${statusCode}`);

                // ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ (ETIMEDOUT, ECONNREFUSED ë“±) ì‹œ ì¬ì‹œë„
                const isNetworkError = !statusCode && (
                    error.code === 'ETIMEDOUT' ||
                    error.code === 'ECONNREFUSED' ||
                    error.code === 'ECONNRESET' ||
                    error.code === 'ENOTFOUND' ||
                    error.code === 'EAI_AGAIN'
                );

                // 429, 401, 403, 502 ì—ëŸ¬ ì‹œ API í‚¤ ìŠ¤ì™€í•‘ ì‹œë„
                // 502: Cloud ëª¨ë¸ ê²Œì´íŠ¸ì›¨ì´ ì¥ì•  (Ollama ê³µì‹ ë¬¸ì„œ)
                if (statusCode === 429 || statusCode === 401 || statusCode === 403 || statusCode === 502) {
                    // ì¬ì‹œë„ íšŸìˆ˜ ì¶”ì  (í‚¤ ê°œìˆ˜ë§Œí¼ ì‹œë„)
                    const retryCount = error.config?._retryCount || 0;
                    const maxRetries = this.apiKeyManager.getTotalKeys() - 1;

                    console.log(`[OllamaClient] ğŸ”„ API í‚¤ ìŠ¤ì™€í•‘ ì‹œë„ ì¤‘... (${retryCount + 1}/${maxRetries + 1})`);
                    const switched = this.apiKeyManager.reportFailure(error);

                    if (switched && error.config && retryCount < maxRetries) {
                        error.config._retryCount = retryCount + 1;
                        const newAuthHeaders = this.apiKeyManager.getAuthHeaders();
                        error.config.headers.Authorization = newAuthHeaders.Authorization;
                        console.log(`[OllamaClient] âœ… ìƒˆ API í‚¤ë¡œ ì¬ì‹œë„ (Key ${this.apiKeyManager.getCurrentKeyIndex() + 1})...`);
                        return this.client.request(error.config);
                    } else {
                        console.log(`[OllamaClient] âš ï¸ ëª¨ë“  í‚¤ ì†Œì§„ - switched: ${switched}, retryCount: ${retryCount}/${maxRetries}`);
                        
                        // ğŸ†• ëª¨ë“  í‚¤ê°€ ì†Œì§„ë˜ì—ˆì„ ë•Œ KeyExhaustionError throw
                        const nextResetTime = this.apiKeyManager.getNextResetTime();
                        if (nextResetTime) {
                            const totalKeys = this.apiKeyManager.getTotalKeys();
                            const keysInCooldown = this.apiKeyManager.getKeysInCooldownCount();
                            throw new KeyExhaustionError(nextResetTime, totalKeys, keysInCooldown);
                        }
                    }
                } else if (isNetworkError && error.config) {
                    // ë„¤íŠ¸ì›Œí¬ ì¼ì‹œ ì¥ì•  ì‹œ ìµœëŒ€ 2íšŒ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
                    const retryCount = error.config._retryCount || 0;
                    const maxNetworkRetries = 2;
                    if (retryCount < maxNetworkRetries) {
                        error.config._retryCount = retryCount + 1;
                        const backoffMs = Math.pow(2, retryCount) * 1000; // 1s, 2s
                        console.log(`[OllamaClient] ğŸ”„ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬(${error.code}) - ${backoffMs}ms í›„ ì¬ì‹œë„ (${retryCount + 1}/${maxNetworkRetries})`);
                        await new Promise(resolve => setTimeout(resolve, backoffMs));
                        return this.client.request(error.config);
                    }
                    console.log(`[OllamaClient] âš ï¸ ë„¤íŠ¸ì›Œí¬ ì¬ì‹œë„ ì†Œì§„ (${error.code})`);
                    // ENOTFOUND/EAI_AGAINì€ í˜¸ìŠ¤íŠ¸(DNS) ë ˆë²¨ ì¥ì•  â€” í‚¤ ë¡œí…Œì´ì…˜ ë¬´ì˜ë¯¸
                    // í‚¤ë³„ ì¥ì• (ETIMEDOUT, ECONNREFUSED ë“±)ë§Œ í‚¤ êµì²´ íŠ¸ë¦¬ê±°
                    if (error.code !== 'ENOTFOUND' && error.code !== 'EAI_AGAIN') {
                        this.apiKeyManager.reportFailure(error);
                    }
                } else {
                    this.apiKeyManager.reportFailure(error);
                }

                throw error;
            }
        );
    }

    /**
     * í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
     * @returns í˜„ì¬ ëª¨ë¸ ì´ë¦„
     */
    get model(): string {
        return this.config.model;
    }

    /**
     * ëª¨ë¸ì´ Cloud ëª¨ë¸(:cloud ì ‘ë¯¸ì‚¬)ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
     *
     * @param model - í™•ì¸í•  ëª¨ë¸ ì´ë¦„
     * @returns Cloud ëª¨ë¸ ì—¬ë¶€
     * @private
     */
    private isCloudModel(model: string): boolean {
        return model?.toLowerCase().endsWith(':cloud') ?? false;
    }

    /**
     * í´ë¼ì´ì–¸íŠ¸ì˜ ê¸°ë³¸ ëª¨ë¸ì„ ë³€ê²½í•˜ê³ , Cloud ëª¨ë¸ ì „í™˜ ì‹œ baseURLì„ ìë™ ê°±ì‹ í•©ë‹ˆë‹¤.
     *
     * Auto-routing ë“±ì—ì„œ ëŸ°íƒ€ì„ì— ëª¨ë¸ì´ ë³€ê²½ë  ë•Œ,
     * Cloud ëª¨ë¸ì´ë©´ OLLAMA_CLOUD_HOSTë¡œ, ë¡œì»¬ ëª¨ë¸ì´ë©´ ì›ë˜ ë…¸ë“œ URLë¡œ ì „í™˜í•©ë‹ˆë‹¤.
     *
     * @param model - ìƒˆë¡œ ì„¤ì •í•  ëª¨ë¸ ì´ë¦„
     */
    setModel(model: string): void {
        const wasCloud = this.isCloudModel(this.config.model);
        const isCloud = this.isCloudModel(model);
        this.config.model = model;

        // Cloud â†” Local ì „í™˜ ì‹œ baseURL ê°±ì‹ 
        if (isCloud && !wasCloud) {
            this.client.defaults.baseURL = OLLAMA_CLOUD_HOST;
            logger.info(`[setModel] ğŸŒ Cloud ëª¨ë¸ ì „í™˜ â†’ ${OLLAMA_CLOUD_HOST} (model: ${model})`);
        } else if (!isCloud && wasCloud) {
            this.client.defaults.baseURL = this.config.baseUrl;
            logger.info(`[setModel] ğŸ  Local ëª¨ë¸ ì „í™˜ â†’ ${this.config.baseUrl} (model: ${model})`);
        }
    }

    /**
     * Ollama ì„œë²„ì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
     *
     * @returns ëª¨ë¸ ëª©ë¡ ì‘ë‹µ (ëª¨ë¸ ì´ë¦„, í¬ê¸°, ìˆ˜ì •ì¼ ë“±)
     * @throws {Error} ì„œë²„ ì—°ê²° ì‹¤íŒ¨ ì‹œ
     */
    async listModels(): Promise<ListModelsResponse> {
        const response = await this.client.get<ListModelsResponse>('/api/tags');
        return response.data;
    }

    /**
     * ëª¨ë¸ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (Ollama POST /api/show).
     *
     * ëª¨ë¸ì˜ ë¼ì´ì„ ìŠ¤, Modelfile, íŒŒë¼ë¯¸í„°, í…œí”Œë¦¿, capabilities ë“±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
     *
     * @param model - ì¡°íšŒí•  ëª¨ë¸ ì´ë¦„
     * @param verbose - ìƒì„¸ ëª¨ë¸ ì •ë³´ í¬í•¨ ì—¬ë¶€
     * @returns ëª¨ë¸ ìƒì„¸ ì •ë³´
     */
    async showModel(model: string, verbose?: boolean): Promise<ShowModelResponse> {
        const request: ShowModelRequest = { model, ...(verbose && { verbose }) };
        const response = await this.client.post<ShowModelResponse>('/api/show', request);
        return response.data;
    }

    /**
     * í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤ (Ollama GET /api/ps).
     *
     * ê° ëª¨ë¸ì˜ VRAM ì‚¬ìš©ëŸ‰, ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´, ë§Œë£Œ ì‹œê°„ ë“±ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
     *
     * @returns ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡
     */
    async listRunningModels(): Promise<PsResponse> {
        const response = await this.client.get<PsResponse>('/api/ps');
        return response.data;
    }

    /**
     * Check API quota before making a request.
     * Throws QuotaExceededError if hourly or weekly limit is exceeded.
     */
    private checkQuota(): void {
        try {
            const tracker = getApiUsageTracker();
            const quota = tracker.getQuotaStatus();

            if (quota.hourly.remaining <= 0 && quota.weekly.remaining <= 0) {
                throw new QuotaExceededError('both', quota.weekly.used, quota.weekly.limit);
            }
            if (quota.hourly.remaining <= 0) {
                throw new QuotaExceededError('hourly', quota.hourly.used, quota.hourly.limit);
            }
            if (quota.weekly.remaining <= 0) {
                throw new QuotaExceededError('weekly', quota.weekly.used, quota.weekly.limit);
            }
        } catch (error) {
            // Re-throw QuotaExceededError, ignore other errors (tracker init failures)
            if (error instanceof QuotaExceededError) {
                throw error;
            }
            logger.warn('Quota check failed (non-blocking):', error);
        }
    }

    /**
     * í…ìŠ¤íŠ¸ ìƒì„± APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (Ollama /api/generate).
     *
     * onToken ì½œë°±ì´ ì œê³µë˜ë©´ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë™ì‘í•˜ì—¬ í† í° ë‹¨ìœ„ë¡œ ì½œë°±ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
     * ì‚¬ìš©ëŸ‰ ì¿¼í„° ê²€ì‚¬ë¥¼ ë¨¼ì € ìˆ˜í–‰í•˜ê³ , ì´ˆê³¼ ì‹œ QuotaExceededErrorë¥¼ throwí•©ë‹ˆë‹¤.
     *
     * @param prompt - ìƒì„±í•  í…ìŠ¤íŠ¸ì˜ í”„ë¡¬í”„íŠ¸
     * @param options - ëª¨ë¸ ì¶”ë¡  ì˜µì…˜ (temperature, top_p ë“±)
     * @param onToken - ìŠ¤íŠ¸ë¦¬ë° ì‹œ í† í° ìˆ˜ì‹  ì½œë°± (ë¯¸ì œê³µ ì‹œ ë¹„ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ)
     * @param images - Base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë°°ì—´ (Vision ëª¨ë¸ìš©)
     * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸ì™€ ì„±ëŠ¥ ë©”íŠ¸ë¦­
     * @throws {QuotaExceededError} ì‹œê°„/ì£¼ê°„ ì‚¬ìš©ëŸ‰ í•œê³„ ì´ˆê³¼ ì‹œ
     */
    async generate(
        prompt: string,
        options?: ModelOptions,
        onToken?: (token: string) => void,
        images?: string[],
        advancedOptions?: {
            think?: ThinkOption;
            format?: FormatOption;
            system?: string;
            keep_alive?: string | number;
        }
    ): Promise<{ response: string; metrics?: UsageMetrics }> {
        this.checkQuota();

        const request: GenerateRequest = {
            model: this.config.model,
            prompt,
            context: this.context,
            stream: !!onToken,
            options,
            images,
            ...(advancedOptions?.think !== undefined && { think: advancedOptions.think }),
            ...(advancedOptions?.format && { format: advancedOptions.format }),
            ...(advancedOptions?.system && { system: advancedOptions.system }),
            ...(advancedOptions?.keep_alive !== undefined && { keep_alive: advancedOptions.keep_alive })
        };

        if (onToken) {
            return this.streamGenerate(request, onToken);
        }

        const response = await this.client.post<GenerateResponse>('/api/generate', request);
        this.context = response.data.context || [];
        return {
            response: response.data.response,
            metrics: {
                total_duration: response.data.total_duration,
                load_duration: response.data.load_duration,
                prompt_eval_count: response.data.prompt_eval_count,
                prompt_eval_duration: response.data.prompt_eval_duration,
                eval_count: response.data.eval_count,
                eval_duration: response.data.eval_duration
            }
        };
    }

    /**
     * ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (ë‚´ë¶€ ë©”ì„œë“œ).
     *
     * NDJSON ìŠ¤íŠ¸ë¦¼ì„ íŒŒì‹±í•˜ì—¬ í† í° ë‹¨ìœ„ë¡œ ì½œë°±ì„ í˜¸ì¶œí•˜ê³ ,
     * ì™„ë£Œ ì‹œ ì „ì²´ ì‘ë‹µê³¼ ë©”íŠ¸ë¦­ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
     * ë²„í¼ë§ ë°©ì‹ìœ¼ë¡œ ì¤„ ë‹¨ìœ„ íŒŒì‹±ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
     *
     * @param request - í…ìŠ¤íŠ¸ ìƒì„± ìš”ì²­ ê°ì²´
     * @param onToken - í† í° ìˆ˜ì‹  ì½œë°±
     * @returns ì „ì²´ ì‘ë‹µ í…ìŠ¤íŠ¸ì™€ ì„±ëŠ¥ ë©”íŠ¸ë¦­
     * @private
     */
    private async streamGenerate(
        request: GenerateRequest,
        onToken: (token: string) => void
    ): Promise<{ response: string; metrics?: UsageMetrics }> {
        const response = await this.client.post('/api/generate', request, {
            responseType: 'stream'
        });

        let fullResponse = '';
        let metrics: UsageMetrics | undefined;

        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const parsed = JSON.parse(line) as GenerateResponse & { error?: string };
                            // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ì‘ë‹µ ì²´í¬ (Ollama ê³µì‹ ë¬¸ì„œ)
                            if (parsed.error) {
                                reject(new Error(`Ollama generate stream error: ${parsed.error}`));
                                return;
                            }
                            const data = parsed;
                            if (data.response) {
                                fullResponse += data.response;
                                onToken(data.response);
                            }
                            // Thinking í•„ë“œ ì²˜ë¦¬ (think=true ì‹œ)
                            if (data.thinking) {
                                fullResponse += data.thinking;
                                onToken(data.thinking);
                            }
                            if (data.done) {
                                if (data.context) {
                                    this.context = data.context;
                                }
                                metrics = {
                                    total_duration: data.total_duration,
                                    load_duration: data.load_duration,
                                    prompt_eval_count: data.prompt_eval_count,
                                    prompt_eval_duration: data.prompt_eval_duration,
                                    eval_count: data.eval_count,
                                    eval_duration: data.eval_duration
                                };
                            }
                        } catch (e) {
                            console.error('[OllamaClient] JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const parsed = JSON.parse(buffer) as GenerateResponse & { error?: string };
                        if (parsed.error) {
                            reject(new Error(`Ollama generate stream error: ${parsed.error}`));
                            return;
                        }
                        const data = parsed;
                        if (data.response) {
                            fullResponse += data.response;
                            onToken(data.response);
                        }
                        if (data.thinking) {
                            fullResponse += data.thinking;
                            onToken(data.thinking);
                        }
                        if (data.done) {
                            metrics = {
                                total_duration: data.total_duration,
                                load_duration: data.load_duration,
                                prompt_eval_count: data.prompt_eval_count,
                                prompt_eval_duration: data.prompt_eval_duration,
                                eval_count: data.eval_count,
                                eval_duration: data.eval_duration
                            };
                        }
                    } catch (e) { /* ignore trailing buffer parse errors */ }
                }
                resolve({ response: fullResponse, metrics });
            });
            response.data.on('error', reject);
        });
    }

    /**
     * ì±„íŒ… APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤ (Ollama /api/chat).
     *
     * Thinking(ì¶”ë¡  ê³¼ì • í‘œì‹œ), êµ¬ì¡°í™”ëœ ì¶œë ¥(JSON Schema), Tool Calling ë“±
     * ê³ ê¸‰ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤. onToken ì½œë°± ì œê³µ ì‹œ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.
     *
     * @param messages - ëŒ€í™” íˆìŠ¤í† ë¦¬ ë©”ì‹œì§€ ë°°ì—´
     * @param options - ëª¨ë¸ ì¶”ë¡  ì˜µì…˜ (temperature, top_p ë“±)
     * @param onToken - ìŠ¤íŠ¸ë¦¬ë° ì‹œ í† í°/Thinking ìˆ˜ì‹  ì½œë°± (token, thinking?)
     * @param advancedOptions - ê³ ê¸‰ ì˜µì…˜ (think: Thinking ëª¨ë“œ, format: ì¶œë ¥ í˜•ì‹, tools: ë„êµ¬ ëª©ë¡)
     * @returns ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ë©”ì‹œì§€ ë° ì„±ëŠ¥ ë©”íŠ¸ë¦­
     * @throws {QuotaExceededError} ì‚¬ìš©ëŸ‰ í•œê³„ ì´ˆê³¼ ì‹œ
     */
    async chat(
        messages: ChatMessage[],
        options?: ModelOptions,
        onToken?: (token: string, thinking?: string) => void,
        advancedOptions?: {
            think?: ThinkOption;
            format?: FormatOption;
            tools?: ToolDefinition[];
            keep_alive?: string | number;
        }
    ): Promise<ChatMessage & { metrics?: UsageMetrics }> {
        this.checkQuota();

        const request: ChatRequest = {
            model: this.config.model,
            messages,
            stream: !!onToken,
            options,
            ...(advancedOptions?.think !== undefined && { think: advancedOptions.think }),
            ...(advancedOptions?.format && { format: advancedOptions.format }),
            ...(advancedOptions?.tools && { tools: advancedOptions.tools }),
            ...(advancedOptions?.keep_alive !== undefined && { keep_alive: advancedOptions.keep_alive })
        };

        if (onToken) {
            return this.streamChat(request, onToken);
        }

        const response = await this.client.post<ChatResponse>('/api/chat', request);
        return {
            ...response.data.message,
            metrics: {
                total_duration: response.data.total_duration,
                load_duration: response.data.load_duration,
                prompt_eval_count: response.data.prompt_eval_count,
                prompt_eval_duration: response.data.prompt_eval_duration,
                eval_count: response.data.eval_count,
                eval_duration: response.data.eval_duration
            }
        };
    }

    /**
     * ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì±„íŒ… ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤ (ë‚´ë¶€ ë©”ì„œë“œ).
     *
     * NDJSON ìŠ¤íŠ¸ë¦¼ì„ íŒŒì‹±í•˜ì—¬ Thinking, Content, Tool Callsë¥¼ êµ¬ë¶„ ì²˜ë¦¬í•©ë‹ˆë‹¤:
     * - thinking í•„ë“œê°€ ìˆìœ¼ë©´ ì¶”ë¡  ê³¼ì •ìœ¼ë¡œ ì½œë°± í˜¸ì¶œ (ë¹ˆ content + thinking)
     * - content í•„ë“œê°€ ìˆìœ¼ë©´ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¡œ ì½œë°± í˜¸ì¶œ
     * - tool_calls í•„ë“œê°€ ìˆìœ¼ë©´ ë„êµ¬ í˜¸ì¶œ ëª©ë¡ ìˆ˜ì§‘
     * - done=true ì‹œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
     *
     * @param request - ì±„íŒ… ìš”ì²­ ê°ì²´
     * @param onToken - í† í°/Thinking ìˆ˜ì‹  ì½œë°±
     * @returns ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ë©”ì‹œì§€ (content, thinking, tool_calls í¬í•¨)
     * @private
     */
    private async streamChat(
        request: ChatRequest,
        onToken: (token: string, thinking?: string) => void
    ): Promise<ChatMessage & { metrics?: UsageMetrics }> {
        const response = await this.client.post('/api/chat', request, {
            responseType: 'stream'
        });

        let fullContent = '';
        let fullThinking = '';
        let toolCalls: ToolCall[] = [];
        let metrics: UsageMetrics | undefined;

        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                // logger.debug(`Data chunk received: ${chunk.length} bytes`); // Log noise reduction
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const parsed = JSON.parse(line) as ChatResponse & { error?: string };
                            // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì—ëŸ¬ ì‘ë‹µ ì²´í¬ (Ollama ê³µì‹ ë¬¸ì„œ)
                            if (parsed.error) {
                                reject(new Error(`Ollama chat stream error: ${parsed.error}`));
                                return;
                            }
                            const data = parsed;

                            // Handle thinking trace
                            if (data.message?.thinking) {
                                fullThinking += data.message.thinking;
                                onToken('', data.message.thinking);
                            }

                            // Handle content
                            if (data.message?.content) {
                                fullContent += data.message.content;
                                onToken(data.message.content);
                            }

                            // Handle tool calls (ìŠ¤íŠ¸ë¦¬ë° ì‹œ ëˆ„ì  â€” Ollama ê³µì‹ ìŠ¤í™)
                            if (data.message?.tool_calls) {
                                toolCalls = [...toolCalls, ...data.message.tool_calls];
                            }

                            if (data.done) {
                                metrics = {
                                    total_duration: data.total_duration,
                                    load_duration: data.load_duration,
                                    prompt_eval_count: data.prompt_eval_count,
                                    prompt_eval_duration: data.prompt_eval_duration,
                                    eval_count: data.eval_count,
                                    eval_duration: data.eval_duration
                                };
                            }
                        } catch (e) {
                            console.error('[OllamaClient] Chat JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const parsed = JSON.parse(buffer) as ChatResponse & { error?: string };
                        if (parsed.error) {
                            reject(new Error(`Ollama chat stream error: ${parsed.error}`));
                            return;
                        }
                        const data = parsed;
                        if (data.message?.thinking) fullThinking += data.message.thinking;
                        if (data.message?.content) {
                            fullContent += data.message.content;
                            onToken(data.message.content);
                        }
                        if (data.message?.tool_calls) toolCalls = [...toolCalls, ...data.message.tool_calls];
                        if (data.done) {
                            metrics = {
                                total_duration: data.total_duration,
                                load_duration: data.load_duration,
                                prompt_eval_count: data.prompt_eval_count,
                                prompt_eval_duration: data.prompt_eval_duration,
                                eval_count: data.eval_count,
                                eval_duration: data.eval_duration
                            };
                        }
                    } catch (e) { /* ignore */ }
                }

                const result: ChatMessage & { metrics?: UsageMetrics } = {
                    role: 'assistant',
                    content: fullContent,
                    metrics
                };

                if (fullThinking) {
                    result.thinking = fullThinking;
                }

                if (toolCalls.length > 0) {
                    result.tool_calls = toolCalls;
                }

                resolve(result);
            });
            response.data.on('error', reject);
        });
    }

    /**
     * í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤ (Ollama /api/embed).
     *
     * í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ê³µê°„ì˜ ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
     * ìœ ì‚¬ë„ ê²€ìƒ‰, í´ëŸ¬ìŠ¤í„°ë§ ë“±ì— í™œìš©ë©ë‹ˆë‹¤.
     *
     * @param input - ì„ë² ë”©í•  í…ìŠ¤íŠ¸ (ë‹¨ì¼ ë¬¸ìì—´ ë˜ëŠ” ë°°ì—´)
     * @param model - ì„ë² ë”© ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸ê°’: 'embeddinggemma')
     * @returns ì„ë² ë”© ë²¡í„° ë°°ì—´ (ì…ë ¥ ê°œìˆ˜ x ì°¨ì›)
     * @throws {Error} ì„ë² ë”© ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€ ì‹œ
     */
    async embed(
        input: string | string[],
        model?: string,
        embedOptions?: {
            truncate?: boolean;
            keep_alive?: string | number;
            options?: ModelOptions;
        }
    ): Promise<number[][]> {
        const request: EmbedRequest = {
            model: model || 'embeddinggemma',
            input,
            ...(embedOptions?.truncate !== undefined && { truncate: embedOptions.truncate }),
            ...(embedOptions?.keep_alive !== undefined && { keep_alive: embedOptions.keep_alive }),
            ...(embedOptions?.options && { options: embedOptions.options })
        };

        const response = await this.client.post<EmbedResponse>('/api/embed', request);
        return response.data.embeddings;
    }

    /**
     * Ollama ì„œë²„ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.
     *
     * ì„œë²„ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ì— GET ìš”ì²­ì„ ë³´ë‚´ ì‘ë‹µ ê°€ëŠ¥ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
     *
     * @returns ì„œë²„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
     */
    async isAvailable(): Promise<boolean> {
        try {
            await this.client.get('/');
            return true;
        } catch {
            return false;
        }
    }

    /**
     * ì—°ì† ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
     *
     * Generate APIì˜ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í† í° ë°°ì—´ì„ ë¹„ì›ë‹ˆë‹¤.
     * ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ë•Œ í˜¸ì¶œí•©ë‹ˆë‹¤.
     */
    clearContext(): void {
        this.context = [];
    }

    // ============================================
    // Ollama Web Search API Methods
    // ============================================

    /**
     * Ollama ê³µì‹ Web Search API
     * https://ollama.com/api/web_search
     */
    async webSearch(query: string, maxResults: number = 5): Promise<WebSearchResponse> {
        const request: WebSearchRequest = {
            query,
            max_results: Math.min(maxResults, 10)
        };

        console.log(`[OllamaClient] ğŸ” Web Search: "${query}"`);

        try {
            // Ollama ê³µì‹ API ì—”ë“œí¬ì¸íŠ¸
            const response = await this.client.post<WebSearchResponse>(
                `${OLLAMA_CLOUD_HOST}/api/web_search`,
                request,
                {
                    baseURL: '', // Override baseURL to use absolute URL
                    headers: {
                        'Content-Type': 'application/json',
                        ...this.apiKeyManager.getAuthHeaders()
                    }
                }
            );

            console.log(`[OllamaClient] âœ… Web Search: ${response.data.results?.length || 0}ê°œ ê²°ê³¼`);
            return response.data;
        } catch (error: unknown) {
            logger.warn('[OllamaClient] ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨:', error);
            return {
                results: [],
                error: error instanceof Error ? error.message : 'Web search failed'
            };
        }
    }

    /**
     * Ollama ê³µì‹ Web Fetch API
     * https://ollama.com/api/web_fetch
     */
    async webFetch(url: string): Promise<WebFetchResponse> {
        const request: WebFetchRequest = { url };

        console.log(`[OllamaClient] ğŸ“¥ Web Fetch: ${url}`);

        try {
            const response = await this.client.post<WebFetchResponse>(
                `${OLLAMA_CLOUD_HOST}/api/web_fetch`,
                request,
                {
                    baseURL: '',
                    headers: {
                        'Content-Type': 'application/json',
                        ...this.apiKeyManager.getAuthHeaders()
                    }
                }
            );

            console.log(`[OllamaClient] âœ… Web Fetch: "${response.data.title}"`);
            return response.data;
        } catch (error: unknown) {
            console.error('[OllamaClient] Web Fetch ì‹¤íŒ¨:', (error instanceof Error ? error.message : String(error)));
            return { title: '', content: '', links: [] };
        }
    }

    // ============================================
    // Multi-turn Tool Calling (Agent Loop)
    // ============================================

    /**
     * Multi-turn Tool Calling Agent Loop ì‹¤í–‰
     * 
     * ë„êµ¬ í˜¸ì¶œì´ ì—†ì„ ë•Œê¹Œì§€ ìë™ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.
     * ê³µì‹ ë¬¸ì„œ: https://docs.ollama.com/capabilities/tool-calling#multi-turn-tool-calling-agent-loop
     * 
     * @example
     * ```typescript
     * const result = await client.runAgentLoop(
     *   [{ role: 'user', content: 'ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜' }],
     *   [weatherTool],
     *   { get_weather: getWeatherFunc },
     *   { onToolCall: (name, args, result) => console.log(`Tool: ${name}`) }
     * );
     * ```
     */
    async runAgentLoop(
        messages: ChatMessage[],
        tools: ToolDefinition[],
        availableFunctions: Record<string, (args: Record<string, unknown>) => unknown | Promise<unknown>>,
        options?: {
            think?: ThinkOption;
            stream?: boolean;
            onToken?: (token: string, thinking?: string) => void;
            onToolCall?: (name: string, args: unknown, result: unknown) => void;
            maxIterations?: number;
        }
    ): Promise<AgentLoopResult> {
        return runAgentLoop({
            model: this.config.model,
            messages,
            tools,
            availableFunctions,
            think: options?.think,
            stream: options?.stream,
            onToken: options?.onToken,
            onToolCall: options?.onToolCall,
            maxIterations: options?.maxIterations
        });
    }
}

/**
 * OllamaClient ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜
 *
 * @param config - Ollama í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ë¶€ë¶„ ì ìš© ê°€ëŠ¥)
 * @returns ìƒˆ OllamaClient ì¸ìŠ¤í„´ìŠ¤
 */
export const createClient = (config?: Partial<OllamaConfig>): OllamaClient => {
    return new OllamaClient(config);
};

/**
 * ğŸ†• íŠ¹ì • ì¸ë±ìŠ¤ì˜ í‚¤-ëª¨ë¸ ìŒìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ìƒì„± (A2Aìš©)
 * @param index API í‚¤ ì¸ë±ìŠ¤ (0-based)
 * @returns í•´ë‹¹ í‚¤-ëª¨ë¸ ìŒìœ¼ë¡œ êµ¬ì„±ëœ OllamaClient
 */
export const createClientForIndex = (index: number): OllamaClient | null => {
    const keyManager = getApiKeyManager();
    const pair = keyManager.getKeyModelPair(index);
    
    if (!pair) {
        console.error(`[OllamaClient] âŒ ì¸ë±ìŠ¤ ${index}ì— í•´ë‹¹í•˜ëŠ” í‚¤-ëª¨ë¸ ìŒì´ ì—†ìŠµë‹ˆë‹¤.`);
        return null;
    }
    
    console.log(`[OllamaClient] ğŸ¯ ì¸ë±ìŠ¤ ${index + 1} í´ë¼ì´ì–¸íŠ¸ ìƒì„±: ${pair.model}`);
    return new OllamaClient({ model: pair.model });
};

/**
 * ğŸ†• ëª¨ë“  í‚¤-ëª¨ë¸ ìŒì— ëŒ€í•´ í´ë¼ì´ì–¸íŠ¸ ë°°ì—´ ìƒì„± (A2A ë³‘ë ¬ ì²˜ë¦¬ìš©)
 * @returns OllamaClient ë°°ì—´
 */
export const createAllClients = (): OllamaClient[] => {
    const keyManager = getApiKeyManager();
    const pairs = keyManager.getAllKeyModelPairs();
    
    console.log(`[OllamaClient] ğŸš€ ${pairs.length}ê°œ A2A í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...`);
    
    const clients = pairs.map(pair => {
        // ê° í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì „ì— í•´ë‹¹ ì¸ë±ìŠ¤ë¡œ í‚¤ ë§¤ë‹ˆì € ì„¤ì •
        const client = new OllamaClient({ model: pair.model });
        return client;
    });
    
    console.log(`[OllamaClient] âœ… ${clients.length}ê°œ A2A í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ`);
    return clients;
};
