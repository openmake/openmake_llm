/**
 * Ollama Cloud Multi-turn Tool Calling Agent Loop
 * 
 * ê³µì‹ ë¬¸ì„œ ì°¸ê³ : https://docs.ollama.com/capabilities/tool-calling#multi-turn-tool-calling-agent-loop
 * 
 * ì´ ëª¨ë“ˆì€ Ollamaì˜ Tool Calling ê¸°ëŠ¥ì„ í™œìš©í•œ Agent Loopë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
 * - Multi-turn ëŒ€í™”ì—ì„œ ìë™ìœ¼ë¡œ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê³  ê²°ê³¼ë¥¼ ë‹¤ì‹œ LLMì— ì „ë‹¬
 * - Streaming ì§€ì›ìœ¼ë¡œ ì‹¤ì‹œê°„ ì‘ë‹µ ê°€ëŠ¥
 * - ë¬´í•œ ë£¨í”„ ë°©ì§€ë¥¼ ìœ„í•œ maxIterations ì„¤ì •
 */

import { Ollama, Message, Tool, ToolCall, ChatResponse } from 'ollama';
import { ChatMessage, ToolDefinition, ThinkOption, UsageMetrics } from './types';

/** Extended Message with optional thinking field (Ollama Native Thinking) */
interface MessageWithThinking extends Message { thinking?: string; }
import { getApiKeyManager } from './api-key-manager';
import { getConfig } from '../config';

const envConfig = getConfig();

/** Tool execution function type â€” takes parsed arguments, returns result */
type ToolFunction = (args: Record<string, unknown>) => unknown | Promise<unknown>;

// Ollama Cloud í˜¸ìŠ¤íŠ¸
const OLLAMA_CLOUD_HOST = 'https://ollama.com';

type OllamaLikeError = {
    status?: number;
    statusCode?: number;
    status_code?: number;
    response?: { status?: number };
    error?: { status?: number };
    message?: string;
    name?: string;
};

function getHttpStatus(error: unknown): number | undefined {
    if (!error || typeof error !== 'object') return undefined;
    const err = error as OllamaLikeError;
    return err.status ?? err.statusCode ?? err.status_code ?? err.response?.status ?? err.error?.status;
}

function isApiKeyExhaustionError(error: unknown): boolean {
    if (!error || typeof error !== 'object') return false;
    const err = error as OllamaLikeError;
    const text = `${err.name || ''} ${err.message || ''}`.toLowerCase();
    return text.includes('keyexhaustion') || text.includes('api key') && text.includes('exhaust');
}

function sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
}

/**
 * Agent Loop ì‹¤í–‰ ì˜µì…˜
 */
export interface AgentLoopOptions {
    /** ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„ */
    model?: string;
    /** ì´ˆê¸° ë©”ì‹œì§€ ëª©ë¡ */
    messages: ChatMessage[];
    /** ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ì •ì˜ */
    tools: ToolDefinition[];
    /** ë„êµ¬ ì´ë¦„ -> ì‹¤í–‰ í•¨ìˆ˜ ë§¤í•‘ */
    availableFunctions: Record<string, ToolFunction>;
    /** Thinking ëª¨ë“œ í™œì„±í™” */
    think?: ThinkOption;
    /** ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ */
    stream?: boolean;
    /** í† í° ì½œë°± (ìŠ¤íŠ¸ë¦¬ë° ì‹œ) */
    onToken?: (token: string, thinking?: string) => void;
    /** ë„êµ¬ í˜¸ì¶œ ì½œë°± */
    onToolCall?: (name: string, args: unknown, result: unknown) => void;
    /** ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€) */
    maxIterations?: number;
}

/**
 * Agent Loop ê²°ê³¼
 */
export interface AgentLoopResult {
    /** ìµœì¢… ì‘ë‹µ ë©”ì‹œì§€ */
    message: ChatMessage;
    /** ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ */
    history: ChatMessage[];
    /** í˜¸ì¶œëœ ë„êµ¬ ëª©ë¡ */
    toolCallsExecuted: Array<{
        name: string;
        arguments: unknown;
        result: unknown;
    }>;
    /** ì‚¬ìš©ëŸ‰ ë©”íŠ¸ë¦­ */
    metrics?: UsageMetrics;
    /** ë°˜ë³µ íšŸìˆ˜ */
    iterations: number;
}

/**
 * ChatMessageë¥¼ Ollama Message í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 */
function toOllamaMessage(msg: ChatMessage): Message {
    const ollamaMsg: Message = {
        role: msg.role as 'system' | 'user' | 'assistant' | 'tool',
        content: msg.content
    };

    if (msg.images) {
        ollamaMsg.images = msg.images as string[];
    }

    if (msg.tool_calls) {
        ollamaMsg.tool_calls = msg.tool_calls.map(tc => ({
            function: {
                name: tc.function.name,
                arguments: tc.function.arguments
            }
        }));
    }

    return ollamaMsg;
}

/**
 * Ollama Messageë¥¼ ChatMessage í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 */
function fromOllamaMessage(msg: Message): ChatMessage {
    const chatMsg: ChatMessage = {
        role: msg.role as 'system' | 'user' | 'assistant' | 'tool',
        content: msg.content
    };

    if (msg.images) {
        chatMsg.images = msg.images as string[];
    }

    if (msg.tool_calls && msg.tool_calls.length > 0) {
        chatMsg.tool_calls = msg.tool_calls.map((tc, index) => ({
            type: 'function' as const,
            function: {
                index,
                name: tc.function.name,
                arguments: tc.function.arguments as Record<string, unknown>
            }
        }));
    }

    return chatMsg;
}

/**
 * ToolDefinitionì„ Ollama Tool í˜•ì‹ìœ¼ë¡œ ë³€í™˜
 */
function toOllamaTool(tool: ToolDefinition): Tool {
    return {
        type: 'function',
        function: {
            name: tool.function.name,
            description: tool.function.description,
            parameters: tool.function.parameters
        }
    };
}

/**
 * Ollama í´ë¼ì´ì–¸íŠ¸ ìƒì„± (Cloud ì§€ì›)
 */
function createOllamaClient(model: string): Ollama {
    const apiKeyManager = getApiKeyManager();
    const isCloud = model?.toLowerCase().endsWith(':cloud');

    const host = isCloud ? OLLAMA_CLOUD_HOST : envConfig.ollamaBaseUrl;

    const ollama = new Ollama({
        host,
        headers: apiKeyManager.getAuthHeaders()
    });

    console.log(`[AgentLoop] ğŸŒ Ollama í´ë¼ì´ì–¸íŠ¸ ìƒì„± - í˜¸ìŠ¤íŠ¸: ${host}, ëª¨ë¸: ${model}`);

    return ollama;
}

/**
 * Multi-turn Tool Calling Agent Loop ì‹¤í–‰
 * 
 * ë„êµ¬ í˜¸ì¶œì´ ì—†ì„ ë•Œê¹Œì§€ ìë™ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ì–´ê°‘ë‹ˆë‹¤.
 * 
 * @example
 * ```typescript
 * const result = await runAgentLoop({
 *   model: 'gemini-3-flash-preview:cloud',
 *   messages: [{ role: 'user', content: 'ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜' }],
 *   tools: [weatherTool],
 *   availableFunctions: { get_weather: getWeather },
 *   onToolCall: (name, args, result) => console.log(`Tool ${name}: ${result}`)
 * });
 * ```
 */
export async function runAgentLoop(options: AgentLoopOptions): Promise<AgentLoopResult> {
    const {
        model = envConfig.ollamaDefaultModel,
        messages: initialMessages,
        tools,
        availableFunctions,
        think = true,
        stream = false,
        onToken,
        onToolCall,
        maxIterations = 10
    } = options;

    void think;

    const ollama = createOllamaClient(model);
    const ollamaTools = tools.map(toOllamaTool);

    // ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ë³µì‚¬
    const messages: Message[] = initialMessages.map(toOllamaMessage);
    const toolCallsExecuted: AgentLoopResult['toolCallsExecuted'] = [];
    let iterations = 0;
    let lastMetrics: UsageMetrics | undefined;

    console.log(`[AgentLoop] ğŸš€ Agent Loop ì‹œì‘ - ëª¨ë¸: ${model}, ë„êµ¬: ${tools.length}ê°œ`);

    while (iterations < maxIterations) {
        iterations++;
        console.log(`[AgentLoop] ğŸ“ ë°˜ë³µ ${iterations}/${maxIterations}`);

        let response: ChatResponse;
        let requestAttempt = 0;

        while (true) {
            try {
                if (stream && onToken) {
                    let content = '';
                    let thinking = '';
                    let toolCalls: ToolCall[] = [];

                    const streamResponse = await ollama.chat({
                        model,
                        messages,
                        tools: ollamaTools,
                        stream: true,
                        options: {
                        }
                    });

                    for await (const chunk of streamResponse) {
                        if ((chunk.message as MessageWithThinking)?.thinking) {
                            thinking += (chunk.message as MessageWithThinking).thinking;
                            onToken('', (chunk.message as MessageWithThinking).thinking!);
                        }

                        if (chunk.message?.content) {
                            content += chunk.message.content;
                            onToken(chunk.message.content);
                        }

                        if (chunk.message?.tool_calls) {
                            toolCalls = chunk.message.tool_calls;
                        }

                        if (chunk.done) {
                            lastMetrics = {
                                total_duration: chunk.total_duration,
                                load_duration: chunk.load_duration,
                                prompt_eval_count: chunk.prompt_eval_count,
                                prompt_eval_duration: chunk.prompt_eval_duration,
                                eval_count: chunk.eval_count,
                                eval_duration: chunk.eval_duration
                            };
                        }
                    }

                    response = {
                        model,
                        created_at: new Date(),
                        message: {
                            role: 'assistant',
                            content,
                            tool_calls: toolCalls.length > 0 ? toolCalls : undefined
                        },
                        done: true,
                        done_reason: toolCalls.length > 0 ? 'tool_calls' : 'stop',
                        total_duration: lastMetrics?.total_duration,
                        load_duration: lastMetrics?.load_duration,
                        prompt_eval_count: lastMetrics?.prompt_eval_count,
                        prompt_eval_duration: lastMetrics?.prompt_eval_duration,
                        eval_count: lastMetrics?.eval_count,
                        eval_duration: lastMetrics?.eval_duration
                    } as ChatResponse;

                    if (thinking) {
                        (response.message as MessageWithThinking).thinking = thinking;
                    }
                } else {
                    response = await ollama.chat({
                        model,
                        messages,
                        tools: ollamaTools,
                        stream: false
                    });

                    lastMetrics = {
                        total_duration: response.total_duration,
                        load_duration: response.load_duration,
                        prompt_eval_count: response.prompt_eval_count,
                        prompt_eval_duration: response.prompt_eval_duration,
                        eval_count: response.eval_count,
                        eval_duration: response.eval_duration
                    };
                }

                break;
            } catch (error: unknown) {
                const status = getHttpStatus(error);
                const isPermanent = status === 401 || status === 403 || status === 404 || isApiKeyExhaustionError(error);

                if (isPermanent) {
                    console.error(`[AgentLoop] âŒ ì˜êµ¬ ì‹¤íŒ¨(${status || 'unknown'}): ${(error instanceof Error ? error.message : String(error))}`);
                    throw error;
                }

                requestAttempt++;
                if (requestAttempt >= maxIterations) {
                    throw error;
                }

                if (status === 429) {
                    const backoffMs = Math.min(1000 * Math.pow(2, requestAttempt - 1), 10000);
                    console.warn(`[AgentLoop] âš ï¸ 429 ì‘ë‹µ - ${backoffMs}ms í›„ ì¬ì‹œë„ (${requestAttempt}/${maxIterations - 1})`);
                    await sleep(backoffMs);
                } else {
                    console.warn(`[AgentLoop] âš ï¸ ìš”ì²­ ì‹¤íŒ¨(${status || 'unknown'}) - ì¬ì‹œë„ (${requestAttempt}/${maxIterations - 1})`);
                }
            }
        }

        // ì‘ë‹µ ë©”ì‹œì§€ë¥¼ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        messages.push(response.message);

        // Thinking ë¡œê·¸
        if ((response.message as MessageWithThinking)?.thinking) {
            console.log(`[AgentLoop] ğŸ§  Thinking: ${(response.message as MessageWithThinking).thinking!.substring(0, 100)}...`);
        }

        // Content ë¡œê·¸
        if (response.message.content) {
            console.log(`[AgentLoop] ğŸ’¬ Content: ${response.message.content.substring(0, 100)}...`);
        }

        // Tool calls í™•ì¸
        const responsToolCalls = response.message.tool_calls ?? [];

        if (responsToolCalls.length === 0) {
            // ë„êµ¬ í˜¸ì¶œ ì—†ìŒ - ë£¨í”„ ì¢…ë£Œ
            console.log(`[AgentLoop] âœ… ë„êµ¬ í˜¸ì¶œ ì—†ìŒ - ë£¨í”„ ì¢…ë£Œ`);
            break;
        }

        // ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
        for (const toolCall of responsToolCalls) {
            const funcName = toolCall.function.name;
            const funcArgs = toolCall.function.arguments;

            console.log(`[AgentLoop] ğŸ”§ ë„êµ¬ í˜¸ì¶œ: ${funcName}(${JSON.stringify(funcArgs)})`);

            if (!(funcName in availableFunctions)) {
                console.warn(`[AgentLoop] âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë„êµ¬: ${funcName}`);
                continue;
            }

            try {
                // ë„êµ¬ ì‹¤í–‰
                const result = await availableFunctions[funcName](funcArgs);
                const resultStr = typeof result === 'string' ? result : JSON.stringify(result);

                console.log(`[AgentLoop] ğŸ“¤ ë„êµ¬ ê²°ê³¼: ${resultStr.substring(0, 100)}...`);

                // ì½œë°± í˜¸ì¶œ
                if (onToolCall) {
                    onToolCall(funcName, funcArgs, result);
                }

                // ì‹¤í–‰ ê¸°ë¡ ì €ì¥
                toolCallsExecuted.push({
                    name: funcName,
                    arguments: funcArgs,
                    result
                });

                // ë„êµ¬ ê²°ê³¼ë¥¼ ë©”ì‹œì§€ì— ì¶”ê°€
                messages.push({
                    role: 'tool',
                    content: resultStr
                });

            } catch (error: unknown) {
                console.error(`[AgentLoop] âŒ ë„êµ¬ ì‹¤í–‰ ì˜¤ë¥˜: ${(error instanceof Error ? error.message : String(error))}`);
                messages.push({
                    role: 'tool',
                    content: `Error: ${(error instanceof Error ? error.message : String(error))}`
                });
            }
        }
    }

    if (iterations >= maxIterations) {
        console.warn(`[AgentLoop] âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜(${maxIterations}) ë„ë‹¬`);
    }

    // ìµœì¢… ê²°ê³¼ êµ¬ì„±
    const lastMessage = messages[messages.length - 1];
    const history = messages.map(fromOllamaMessage);

    console.log(`[AgentLoop] ğŸ Agent Loop ì™„ë£Œ - ë°˜ë³µ: ${iterations}, ë„êµ¬ í˜¸ì¶œ: ${toolCallsExecuted.length}ê°œ`);

    return {
        message: fromOllamaMessage(lastMessage),
        history,
        toolCallsExecuted,
        metrics: lastMetrics,
        iterations
    };
}

/**
 * ë‹¨ì¼ ë„êµ¬ í˜¸ì¶œ ì‹¤í–‰ (Agent Loop ì‚¬ìš©)
 * 
 * ë‹¨ìˆœí•œ ë‹¨ì¼ ë„êµ¬ í˜¸ì¶œ ì‹œë‚˜ë¦¬ì˜¤ì— ì‚¬ìš©ë©ë‹ˆë‹¤.
 */
export async function executeSingleToolCall(
    model: string,
    prompt: string,
    tools: ToolDefinition[],
    availableFunctions: Record<string, ToolFunction>,
    options?: {
        think?: ThinkOption;
        onToken?: (token: string, thinking?: string) => void;
    }
): Promise<AgentLoopResult> {
    return runAgentLoop({
        model,
        messages: [{ role: 'user', content: prompt }],
        tools,
        availableFunctions,
        think: options?.think,
        stream: !!options?.onToken,
        onToken: options?.onToken,
        maxIterations: 3  // ë‹¨ì¼ í˜¸ì¶œì´ë¯€ë¡œ ì ì€ ë°˜ë³µ
    });
}

/**
 * MCP Toolì„ Ollama Toolë¡œ ë³€í™˜í•˜ëŠ” ì–´ëŒ‘í„°
 */
export function mcpToolToOllamaTool(mcpTool: {
    tool: {
        name: string;
        description: string;
        inputSchema: Record<string, unknown>;
    };
}): ToolDefinition {
    return {
        type: 'function',
        function: {
            name: mcpTool.tool.name,
            description: mcpTool.tool.description,
            parameters: mcpTool.tool.inputSchema as ToolDefinition['function']['parameters']
        }
    };
}

/**
 * ì—¬ëŸ¬ MCP Toolsë¥¼ Ollama Toolsë¡œ ë³€í™˜
 */
export function mcpToolsToOllamaTools(mcpTools: Array<{
    tool: {
        name: string;
        description: string;
        inputSchema: Record<string, unknown>;
    };
}>): ToolDefinition[] {
    return mcpTools.map(mcpToolToOllamaTool);
}
