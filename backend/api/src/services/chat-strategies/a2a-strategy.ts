import { OllamaClient } from '../../ollama/client';
import type { ChatStrategy, A2AStrategyContext, A2AStrategyResult } from './types';

const A2A_MODELS = {
    primary: 'gpt-oss:120b-cloud',
    secondary: 'gemini-3-flash-preview:cloud',
    synthesizer: 'gemini-3-flash-preview:cloud',
} as const;

const A2A_SYNTHESIS_SYSTEM_PROMPT = [
    'ë‹¹ì‹ ì€ ë‘ AI ëª¨ë¸ì˜ ì‘ë‹µì„ ì¢…í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.',
    '',
    '## ì¢…í•© ì§€ì¹¨',
    '1. ê° ì‘ë‹µì—ì„œ ê°€ì¥ ê°•ë ¥í•˜ê³  ì •í™•í•œ í¬ì¸íŠ¸ë¥¼ ì‹ë³„í•˜ì„¸ìš”.',
    '2. ëª¨ìˆœë˜ëŠ” ë‚´ìš©ì´ ìˆìœ¼ë©´ ë” ì •í™•í•˜ê³  ìƒì„¸í•œ ìª½ì„ ì±„íƒí•˜ì„¸ìš”.',
    '3. ì–‘ìª½ì˜ ë³´ì™„ì  ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê²°í•©í•˜ì„¸ìš”.',
    '4. ì½”ë“œ ë¸”ë¡, ë§ˆí¬ë‹¤ìš´ ì„œì‹, êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ëŠ” ê·¸ëŒ€ë¡œ ë³´ì¡´í•˜ì„¸ìš”.',
    '5. ì›ë³¸ ì§ˆë¬¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ì‘ë‹µí•˜ì„¸ìš”.',
    '',
    '## ì¶œë ¥ í˜•ì‹',
    'ìµœì¢… ì¢…í•© ë‹µë³€ë§Œ ì¶œë ¥í•˜ì„¸ìš”. "ëª¨ë¸ Aì— ë”°ë¥´ë©´..." ê°™ì€ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.',
].join('\n');

export class A2AStrategy implements ChatStrategy<A2AStrategyContext, A2AStrategyResult> {
    async execute(context: A2AStrategyContext): Promise<A2AStrategyResult> {
        const startTime = Date.now();

        const clientA = new OllamaClient({ model: A2A_MODELS.primary });
        const clientB = new OllamaClient({ model: A2A_MODELS.secondary });

        console.log(`[ChatService] ğŸ”€ A2A ë³‘ë ¬ ìš”ì²­: ${A2A_MODELS.primary} + ${A2A_MODELS.secondary}`);

        const [resultA, resultB] = await Promise.allSettled([
            clientA.chat(context.messages, context.chatOptions),
            clientB.chat(context.messages, context.chatOptions),
        ]);

        if (context.abortSignal?.aborted) {
            throw new Error('ABORTED');
        }

        const responseA = resultA.status === 'fulfilled' ? resultA.value.content : null;
        const responseB = resultB.status === 'fulfilled' ? resultB.value.content : null;
        const durationParallel = Date.now() - startTime;

        console.log(`[ChatService] ğŸ”€ A2A ë³‘ë ¬ ì™„ë£Œ (${durationParallel}ms): ` +
            `${A2A_MODELS.primary}=${resultA.status}, ${A2A_MODELS.secondary}=${resultB.status}`);

        if (!responseA && !responseB) {
            console.warn('[ChatService] âš ï¸ A2A ì–‘ìª½ ëª¨ë‘ ì‹¤íŒ¨');
            if (resultA.status === 'rejected') console.warn(`  ${A2A_MODELS.primary}: ${resultA.reason}`);
            if (resultB.status === 'rejected') console.warn(`  ${A2A_MODELS.secondary}: ${resultB.reason}`);
            return { response: '', succeeded: false };
        }

        if (!responseA || !responseB) {
            const singleResponse = (responseA || responseB) as string;
            const succeededModel = responseA ? A2A_MODELS.primary : A2A_MODELS.secondary;
            console.log(`[ChatService] ğŸ”€ A2A ë‹¨ì¼ ì‘ë‹µ ì‚¬ìš©: ${succeededModel}`);

            const header = `> ğŸ¤– *${succeededModel} ë‹¨ë… ì‘ë‹µ*\n\n`;
            for (const char of header) {
                context.onToken(char);
            }
            for (const char of singleResponse) {
                context.onToken(char);
            }

            return {
                response: header + singleResponse,
                succeeded: true,
            };
        }

        console.log(`[ChatService] ğŸ”€ A2A ì¢…í•© í•©ì„± ì‹œì‘ (synthesizer: ${A2A_MODELS.synthesizer})`);

        const userMessage = [...context.messages].reverse().find((m) => m.role === 'user')?.content || '';

        const synthesisUserMessage = [
            '## ì›ë³¸ ì§ˆë¬¸',
            userMessage,
            '',
            `## Response A (${A2A_MODELS.primary})`,
            responseA,
            '',
            `## Response B (${A2A_MODELS.secondary})`,
            responseB,
            '',
            'ìœ„ ë‘ ì‘ë‹µì„ ì¢…í•©í•˜ì—¬ ìµœê³  í’ˆì§ˆì˜ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.',
        ].join('\n');

        const synthesizerClient = new OllamaClient({ model: A2A_MODELS.synthesizer });
        let fullSynthesis = '';

        const header = `> ğŸ”€ *${A2A_MODELS.primary} + ${A2A_MODELS.secondary} A2A ì¢…í•© ë‹µë³€*\n\n`;
        for (const char of header) {
            context.onToken(char);
        }

        await synthesizerClient.chat(
            [
                { role: 'system', content: A2A_SYNTHESIS_SYSTEM_PROMPT },
                { role: 'user', content: synthesisUserMessage },
            ],
            { temperature: 0.3 },
            (token) => {
                fullSynthesis += token;
                context.onToken(token);
            }
        );

        const totalDuration = Date.now() - startTime;
        console.log(`[ChatService] âœ… A2A ì¢…í•© ì™„ë£Œ: ë³‘ë ¬=${durationParallel}ms, í•©ì„±=${totalDuration - durationParallel}ms, ì´=${totalDuration}ms`);

        return {
            response: header + fullSynthesis,
            succeeded: true,
        };
    }
}
