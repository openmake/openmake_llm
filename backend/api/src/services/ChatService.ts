/**
 * ============================================================
 * ChatService - AI ì±„íŒ… ì„œë¹„ìŠ¤ ëª¨ë“ˆ
 * ============================================================
 * 
 * LLMì„ í†µí•œ ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
 * 
 * @module services/ChatService
 * @description
 * - ì—ì´ì „íŠ¸ ìë™ ë¼ìš°íŒ… ë° ì„ íƒ
 * - ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì£¼ì… ë° ë¶„ì„
 * - MCP ë„êµ¬ ì‹¤í–‰ (Agent Loop)
 * - ë©€í‹° ì—ì´ì „íŠ¸ í† ë¡  ëª¨ë“œ
 * - API ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ëª¨ë‹ˆí„°ë§
 */

import { OllamaClient } from '../ollama/client';
import { routeToAgent, getAgentSystemMessage, AGENTS } from '../agents';
import { getPromptConfig } from '../chat/prompt';
import { getSequentialThinkingServer, applySequentialThinking } from '../mcp/sequential-thinking';
import { getGptOssTaskPreset, isGeminiModel } from '../ollama/types';
import { DocumentResult } from '../documents/processor';
import { DocumentStore } from '../documents/store';
import { createDiscussionEngine, DiscussionProgress, DiscussionResult } from '../agents/discussion-engine';
import { getApiUsageTracker } from '../ollama/api-usage-tracker';
import { getApiKeyManager } from '../ollama/api-key-manager';
import { builtInTools } from '../mcp/tools';
import { ToolDefinition } from '../ollama/types';
import { UserTier } from '../data/user-manager';
import { canUseTool } from '../mcp/tool-tiers';
import { UserContext } from '../mcp/user-sandbox';

/**
 * Chat message structure for conversation history
 * Uses Record<string, unknown> for flexibility with existing code
 */
export interface ChatHistoryMessage {
    role: 'user' | 'assistant' | 'system' | 'tool';
    content: string;
    images?: string[];
    tool_calls?: Array<{
        type?: string;
        function: {
            name: string;
            arguments: Record<string, unknown> | string;
        };
    }>;
    [key: string]: unknown;
}

/**
 * Agent information for selection callback
 */
export interface AgentSelectionInfo {
    type?: string;
    name?: string;
    emoji?: string;
    phase?: string;
    reason?: string;
    confidence?: number;
    [key: string]: unknown;
}

/**
 * Tool call structure from LLM response
 */
export interface ToolCallInfo {
    type?: string;
    function: {
        name: string;
        arguments: Record<string, unknown>;
    };
}

/**
 * Web search result type
 */
export interface WebSearchResult {
    title: string;
    url: string;
    snippet?: string;
}

/**
 * Web search function type
 */
export type WebSearchFunction = (
    query: string,
    options?: { maxResults?: number }
) => Promise<WebSearchResult[]>;

/**
 * Chat metrics interface - flexible to accommodate various metric types
 */
export interface ChatMetrics {
    model?: string;
    tokens?: number;
    duration?: number;
    [key: string]: unknown;
}

/**
 * ì±„íŒ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì„¤ì •
 * @interface ChatServiceConfig
 */
export interface ChatServiceConfig {
    /** Ollama í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ */
    client: OllamaClient;
    /** ì‚¬ìš©í•  LLM ëª¨ë¸ëª… */
    model: string;
}

/**
 * ì±„íŒ… ë©”ì‹œì§€ ìš”ì²­ ì¸í„°í˜ì´ìŠ¤
 * @interface ChatMessageRequest
 */
export interface ChatMessageRequest {
    /** ì‚¬ìš©ì ë©”ì‹œì§€ ë‚´ìš© */
    message: string;
    /** ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì ) */
    history?: any[];
    /** ì°¸ì¡° ë¬¸ì„œ ID (ì„ íƒì ) */
    docId?: string;
    /** ì´ë¯¸ì§€ ë°ì´í„° ë°°ì—´ - base64 ì¸ì½”ë”© (ì„ íƒì ) */
    images?: string[];
    /** ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒì ) */
    webSearchContext?: string;
    /** ë©€í‹° ì—ì´ì „íŠ¸ í† ë¡  ëª¨ë“œ í™œì„±í™” ì—¬ë¶€ */
    discussionMode?: boolean;
    /** íŒ”ë¼ë§ˆ Native Thinking ëª¨ë“œ í™œì„±í™” ì—¬ë¶€ */
    thinkingMode?: boolean;
    /** Thinking ë ˆë²¨ (low/medium/high) */
    thinkingLevel?: 'low' | 'medium' | 'high';
    /** ğŸ†• ì‚¬ìš©ì ID (ë©”ëª¨ë¦¬ ì„œë¹„ìŠ¤ ì—°ë™ìš©) */
    userId?: string;
    /** ğŸ†• ì‚¬ìš©ì ì—­í•  (admin/user/guest) - ë„êµ¬ ê¶Œí•œ ê²°ì •ì— ì‚¬ìš© */
    userRole?: 'admin' | 'user' | 'guest';
    /** ğŸ†• ì‚¬ìš©ì ë“±ê¸‰ (free/pro/enterprise) - ëª…ì‹œì  ì§€ì • ì‹œ ì‚¬ìš© */
    userTier?: UserTier;
}

/**
 * AI ì±„íŒ… ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
 * 
 * LLMì„ í†µí•œ ë©”ì‹œì§€ ì²˜ë¦¬, ì—ì´ì „íŠ¸ ë¼ìš°íŒ…, ë„êµ¬ ì‹¤í–‰ ë“±ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
 * 
 * @class ChatService
 * @example
 * const chatService = new ChatService(ollamaClient);
 * const response = await chatService.processMessage({
 *     message: 'ì•ˆë…•í•˜ì„¸ìš”',
 *     history: []
 * }, uploadedDocs, (token) => console.log(token));
 */
export class ChatService {
    /** Ollama LLM í´ë¼ì´ì–¸íŠ¸ */
    private client: OllamaClient;
    
    /** ğŸ†• í˜„ì¬ ìš”ì²­ì˜ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ (ë„êµ¬ ê¶Œí•œ ê²€ì¦ìš©) */
    private currentUserContext: UserContext | null = null;

    /**
     * ChatService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     * @param client - Ollama í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
     */
    constructor(client: OllamaClient) {
        this.client = client;
    }
    
    /**
     * ğŸ†• ì‚¬ìš©ì ì—­í• ì— ë”°ë¥¸ ë„êµ¬ ë“±ê¸‰ ê²°ì •
     * - admin â†’ enterprise (ëª¨ë“  ë„êµ¬ í—ˆìš©)
     * - user â†’ ëª…ì‹œëœ tier ë˜ëŠ” free
     * - guest â†’ free
     */
    private resolveUserTier(userRole?: 'admin' | 'user' | 'guest', explicitTier?: UserTier): UserTier {
        // adminì€ í•­ìƒ enterprise
        if (userRole === 'admin') {
            return 'enterprise';
        }
        
        // ëª…ì‹œì ìœ¼ë¡œ ì§€ì •ëœ tierê°€ ìˆìœ¼ë©´ ì‚¬ìš©
        if (explicitTier) {
            return explicitTier;
        }
        
        // ê¸°ë³¸ê°’: free
        return 'free';
    }
    
    /**
     * ğŸ†• í˜„ì¬ ìš”ì²­ì˜ ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
     */
    private setUserContext(userId: string, userRole?: 'admin' | 'user' | 'guest', userTier?: UserTier): void {
        const tier = this.resolveUserTier(userRole, userTier);
        this.currentUserContext = {
            userId: userId || 'guest',
            tier,
            role: userRole || 'guest'
        };
        console.log(`[ChatService] ğŸ” ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì •: userId=${userId}, role=${userRole}, tier=${tier}`);
    }

    /**
     * ì±„íŒ… ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
     * 
     * ì²˜ë¦¬ íë¦„:
     * 1. í† ë¡  ëª¨ë“œ í™•ì¸ ë° ë¶„ê¸°
     * 2. ì—ì´ì „íŠ¸ ìë™ ì„ íƒ (LLM ê¸°ë°˜)
     * 3. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
     * 4. Sequential Thinking ì ìš©
     * 5. Agent Loop - MCP ë„êµ¬ ì‹¤í–‰
     * 6. API ì‚¬ìš©ëŸ‰ ì¶”ì 
     * 
     * @param req - ì±„íŒ… ë©”ì‹œì§€ ìš”ì²­ ê°ì²´
     * @param uploadedDocuments - ì—…ë¡œë“œëœ ë¬¸ì„œ ë§µ
     * @param onToken - í† í° ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
     * @param onAgentSelected - ì—ì´ì „íŠ¸ ì„ íƒ ì•Œë¦¼ ì½œë°± (ì„ íƒì )
     * @param onDiscussionProgress - í† ë¡  ì§„í–‰ ìƒí™© ì½œë°± (ì„ íƒì )
     * @returns ìµœì¢… ì‘ë‹µ ë¬¸ìì—´
     */
    async processMessage(
        req: ChatMessageRequest,
        uploadedDocuments: DocumentStore,
        onToken: (token: string) => void,
        onAgentSelected?: (agent: any) => void,
        onDiscussionProgress?: (progress: DiscussionProgress) => void
    ): Promise<string> {
        const { message, history, docId, images, webSearchContext, discussionMode, thinkingMode, thinkingLevel, userId, userRole, userTier } = req;

        // ğŸ†• ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì • (ë„êµ¬ ê¶Œí•œ ê²€ì¦ìš©)
        this.setUserContext(userId || 'guest', userRole, userTier);

        // ğŸ¯ í† ë¡  ëª¨ë“œ ì²˜ë¦¬
        if (discussionMode) {
            return this.processMessageWithDiscussion(req, uploadedDocuments, onToken, onDiscussionProgress);
        }

        const startTime = Date.now(); // ğŸ†• ì‘ë‹µ ì‹œê°„ ì¶”ì 
        let fullResponse = '';

        // ğŸš€ 1. ì—ì´ì „íŠ¸ ìë™ ì„ íƒ (LLM ê¸°ë°˜)
        const agentSelection = await routeToAgent(message || '');
        const agentSystemMessage = getAgentSystemMessage(agentSelection);
        const selectedAgent = AGENTS[agentSelection.primaryAgent];

        console.log(`[ChatService] ì—ì´ì „íŠ¸: ${selectedAgent.emoji} ${selectedAgent.name}`);

        // ì—ì´ì „íŠ¸ ì„ íƒ ì •ë³´ ì½œë°± í˜¸ì¶œ
        if (onAgentSelected && selectedAgent) {
            onAgentSelected({
                type: agentSelection.primaryAgent,
                name: selectedAgent.name,
                emoji: selectedAgent.emoji,
                phase: agentSelection.phase || 'planning',
                reason: agentSelection.reason || '',
                confidence: agentSelection.confidence || 0.5
            });
        }

        // ğŸ“„ 2. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        let documentContext = '';
        let documentImages: string[] = [];

        if (docId) {
            const doc = uploadedDocuments.get(docId);
            if (doc) {
                // í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
                let docText = doc.text || '';
                const maxChars = isGeminiModel(this.client.model) ? 100000 : 30000;

                if (docText.length > maxChars) {
                    const half = Math.floor(maxChars / 2);
                    const front = docText.substring(0, half);
                    const back = docText.substring(docText.length - half);
                    docText = `${front}\n\n... [ì¤‘ê°„ ë‚´ìš© ìƒëµ] ...\n\n${back}`;
                }

                documentContext = `## ğŸ“š REFERENCE DOCUMENT: ${doc.filename}\n` +
                    `Type: ${doc.type.toUpperCase()}\n` +
                    `Length: ${doc.text.length} chars\n\n` +
                    `CONTENT:\n---\n${docText}\n---\n\n` +
                    `Please analyze the document above and answer the user's question.\n\n`;

                // ë¹„ì „ ë°ì´í„° ì£¼ì…
                if (['image', 'pdf'].includes(doc.type) && doc.info?.base64) {
                    documentImages.push(doc.info.base64);
                }
            }
        }

        // ğŸ¤” 3. Sequential Thinking ì ìš© (ì‚¬ìš©ìê°€ Thinking Mode í™œì„±í™” ì‹œì—ë§Œ)
        const thinkingServer = getSequentialThinkingServer();
        // thinkingServer.reset(); // í•„ìš” ì‹œ ë¦¬ì…‹
        let enhancedUserMessage = applySequentialThinking(message, thinkingMode === true);

        // âœ‰ï¸ 4. ìµœì¢… ë©”ì‹œì§€ ì¡°ë¦½
        let finalEnhancedMessage = '';
        if (documentContext) finalEnhancedMessage += documentContext;
        if (webSearchContext) finalEnhancedMessage += webSearchContext;
        finalEnhancedMessage += `\n## USER QUESTION\n${enhancedUserMessage}`;

        // âš™ï¸ 5. í”„ë¡¬í”„íŠ¸ ë° ì˜µì…˜ ì„¤ì •
        const promptConfig = getPromptConfig(message);
        let chatOptions = promptConfig.options || {};

        if (docId) {
            const docPreset = getGptOssTaskPreset('document');
            chatOptions = { ...docPreset, ...chatOptions };
        }

        const currentImages = [...(images || []), ...documentImages];



        // ğŸ—£ï¸ 6. LLM í˜¸ì¶œ (Chat vs Generate) with Agent Loop
        let metrics: any = {};
        const maxTurns = 5;
        let currentTurn = 0;
        let finalResponse = '';

        // Prepare initial history
        let currentHistory: any[] = [];
        if (history && history.length > 0) {
            const combinedSystemPrompt = agentSystemMessage
                ? `${agentSystemMessage}\n\n---\n\n${promptConfig.systemPrompt}`
                : promptConfig.systemPrompt;

            currentHistory = [
                { role: 'system', content: combinedSystemPrompt },
                ...history.map((h: any) => ({
                    role: h.role,
                    content: h.content,
                    images: h.images
                }))
            ];
        } else {
            const combinedSystemPrompt = agentSystemMessage
                ? `${agentSystemMessage}\n\n---\n\n${promptConfig.systemPrompt}`
                : promptConfig.systemPrompt;
            currentHistory = [{ role: 'system', content: combinedSystemPrompt }];
        }

        // Add user message
        currentHistory.push({
            role: 'user',
            content: finalEnhancedMessage,
            ...(currentImages.length > 0 && { images: currentImages })
        });

        // Agent Loop
        while (currentTurn < maxTurns) {
            currentTurn++;
            console.log(`[ChatService] ğŸ”„ Agent Loop Turn ${currentTurn}/${maxTurns}`);

            // Prepare tools (convert MCP tools to Ollama ToolDefinition format)
            // MCP uses 'inputSchema', Ollama expects 'parameters' wrapped in 'function'
            const allowedTools = builtInTools.map(t => ({
                type: 'function' as const,
                function: {
                    name: t.tool.name,
                    description: t.tool.description,
                    parameters: t.tool.inputSchema  // inputSchema â†’ parameters ë§¤í•‘
                }
            }));

            // Call Chat API with Thinking Mode support
            const thinkOption = thinkingMode ? (thinkingLevel || 'high') : undefined;
            const response = await this.client.chat(
                currentHistory,
                chatOptions,
                (token) => {
                    // Only stream content tokens for the final answer or intermediate thoughts if we want
                    // For now, simple streaming of content
                    if (!token.includes('tool_calls')) {
                        fullResponse += token;
                        onToken(token);
                    }
                },
                {
                    tools: allowedTools as any[],
                    think: thinkOption  // ğŸ§  Ollama Native Thinking
                }
            );

            // Capture metrics (accumulate or last?)
            // Ideally accumulate, but for now take the last one or significant one
            if (response.metrics) metrics = response.metrics;

            // Add assistant response to history
            const assistantMessage = {
                role: 'assistant',
                content: response.content || '',
                tool_calls: response.tool_calls
            };
            currentHistory.push(assistantMessage);

            // Check for tool calls
            if (response.tool_calls && response.tool_calls.length > 0) {
                console.log(`[ChatService] ğŸ› ï¸ Tool Calls detected: ${response.tool_calls.length}`);

                // Execute tools
                for (const toolCall of response.tool_calls) {
                    const toolResult = await this.executeToolCall(toolCall);

                    // Add tool result to history
                    currentHistory.push({
                        role: 'tool',
                        content: toolResult, // Result must be string
                        // Ollama/OpenAI expects 'tool_call_id' reference usually, 
                        // but Ollama's current implementation might just need role: tool?
                        // Checking Ollama docs: messages should have 'role': 'tool', 'content': result
                        // And usually needs to match the function call.
                        // However, Ollama generic implementation details specifically for 'tool' role:
                        // "messages": [ ... { "role": "tool", "content": "..." } ]
                    });
                }
                // Loop continues to let LLM process the tool result
            } else {
                // No tool calls, we are done
                finalResponse = response.content || '';
                break;
            }
        }

        // ğŸ†• API ì‚¬ìš©ëŸ‰ ì¶”ì  (í‚¤ë³„ ì¶”ì  í¬í•¨) ë° ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§
        try {
            const usageTracker = getApiUsageTracker();
            const keyManager = getApiKeyManager();
            const currentKey = keyManager.getCurrentKey();

            const responseTime = Date.now() - startTime;
            const tokenCount = fullResponse.length; // Fallback estimate

            // 1. API Usage Tracker (Persistent)
            usageTracker.recordRequest({
                tokens: tokenCount,
                responseTime: responseTime,
                model: this.client.model,
                apiKeyId: currentKey ? currentKey.substring(0, 8) : undefined,
                // New logic: if available
                // preciseMetrics: ...
            });

            // 2. Metrics Collector (Real-time Memory)
            // ì§€ì—° ë¡œë”©ìœ¼ë¡œ ìˆœí™˜ ì°¸ì¡° ë°©ì§€ ê°€ëŠ¥ì„± ê³ ë ¤
            try {
                const { getMetrics } = require('../monitoring/metrics');
                const metricsCollector = getMetrics();

                metricsCollector.incrementCounter('chat_requests_total', 1, { model: this.client.model });
                metricsCollector.recordResponseTime(responseTime, this.client.model);
                metricsCollector.recordTokenUsage(tokenCount, this.client.model);

                if (currentKey) {
                    metricsCollector.incrementCounter('api_key_usage', 1, { keyId: currentKey.substring(0, 8) });
                }
            } catch (e) {
                console.warn('[ChatService] MetricsCollector ê¸°ë¡ ì‹¤íŒ¨:', e);
            }

            // 3. Analytics System (Analysis)
            try {
                const { getAnalyticsSystem } = require('../monitoring/analytics');
                const analytics = getAnalyticsSystem();

                // ì—ì´ì „íŠ¸ ì´ë¦„ í™•ì¸
                const agentName = selectedAgent ? selectedAgent.name : 'General Chat';
                const agentId = agentSelection?.primaryAgent || 'general';

                analytics.recordAgentRequest(
                    agentId,
                    agentName,
                    responseTime,
                    true, // success
                    tokenCount
                );

                // ì¿¼ë¦¬ ë¶„ì„ ê¸°ë¡
                analytics.recordQuery(message);
            } catch (e) {
                console.warn('[ChatService] AnalyticsSystem ê¸°ë¡ ì‹¤íŒ¨:', e);
            }

        } catch (e) {
            console.error('[ChatService] ëª¨ë‹ˆí„°ë§ ë°ì´í„° ê¸°ë¡ ì‹¤íŒ¨:', e);
        }

        return fullResponse;
    }

    /**
     * ë©€í‹° ì—ì´ì „íŠ¸ í† ë¡  ëª¨ë“œë¡œ ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
     * 
     * ì—¬ëŸ¬ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ê°€ í•˜ë‚˜ì˜ ì£¼ì œì— ëŒ€í•´ í† ë¡ í•˜ê³ ,
     * ê°ìì˜ ì˜ê²¬ì„ ì œì‹œí•œ í›„ ì¢…í•© ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
     * 
     * ğŸ†• ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì ìš©:
     * - ì—…ë¡œë“œëœ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬
     * - ëŒ€í™” íˆìŠ¤í† ë¦¬ ì „ë‹¬
     * - ì›¹ ê²€ìƒ‰ ê²°ê³¼ ì „ë‹¬
     * - ì‚¬ìš©ì ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì „ë‹¬ (í–¥í›„ MemoryService ì—°ë™)
     * 
     * @param req - ì±„íŒ… ë©”ì‹œì§€ ìš”ì²­
     * @param uploadedDocuments - ì—…ë¡œë“œëœ ë¬¸ì„œ ë§µ
     * @param onToken - í† í° ìŠ¤íŠ¸ë¦¬ë° ì½œë°±
     * @param onProgress - í† ë¡  ì§„í–‰ ìƒí™© ì½œë°± (ì„ íƒì )
     * @returns í¬ë§·íŒ…ëœ í† ë¡  ê²°ê³¼ ë¬¸ìì—´
     */
    async processMessageWithDiscussion(
        req: ChatMessageRequest,
        uploadedDocuments: DocumentStore,
        onToken: (token: string) => void,
        onProgress?: (progress: DiscussionProgress) => void
    ): Promise<string> {
        const { message, docId, history, webSearchContext, images, userId } = req;

        console.log('[ChatService] ğŸ¯ ë©€í‹° ì—ì´ì „íŠ¸ í† ë¡  ëª¨ë“œ ì‹œì‘');

        // ========================================
        // ğŸ†• ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§: ëª¨ë“  ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘
        // ========================================
        
        // 1. ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        let documentContext = '';
        let documentImages: string[] = [];
        
        if (docId) {
            const doc = uploadedDocuments.get(docId);
            if (doc) {
                let docText = doc.text || '';
                const maxChars = 30000; // í† ë¡  ëª¨ë“œì—ì„œëŠ” ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ í—ˆìš©
                
                if (docText.length > maxChars) {
                    const half = Math.floor(maxChars / 2);
                    docText = `${docText.substring(0, half)}\n... [ì¤‘ê°„ ìƒëµ] ...\n${docText.substring(docText.length - half)}`;
                }
                
                documentContext = `ğŸ“š ë¬¸ì„œ: ${doc.filename} (${doc.type})\n` +
                    `ê¸¸ì´: ${doc.text.length}ì\n\n${docText}`;
                    
                console.log(`[ChatService] ğŸ“„ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì ìš©: ${doc.filename} (${docText.length}ì)`);
                
                // ğŸ†• ì´ë¯¸ì§€/PDFì—ì„œ ë¹„ì „ ë°ì´í„° ì¶”ì¶œ
                if (['image', 'pdf'].includes(doc.type) && doc.info?.base64) {
                    documentImages.push(doc.info.base64);
                    console.log(`[ChatService] ğŸ–¼ï¸ ë¬¸ì„œ ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œë¨`);
                }
            }
        }
        
        // 2. ëŒ€í™” íˆìŠ¤í† ë¦¬ ë³€í™˜
        const conversationHistory = history?.map(h => ({
            role: h.role as string,
            content: h.content as string
        })) || [];
        
        if (conversationHistory.length > 0) {
            console.log(`[ChatService] ğŸ’¬ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì ìš©: ${conversationHistory.length}ê°œ ë©”ì‹œì§€`);
        }
        
        // 3. ì›¹ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸
        if (webSearchContext) {
            console.log(`[ChatService] ğŸ” ì›¹ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸ ì ìš©: ${webSearchContext.length}ì`);
        }
        
        // ğŸ†• 4. ì‚¬ìš©ì ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ (MemoryService ì—°ë™)
        let userMemoryContext = '';
        if (userId && userId !== 'guest') {
            try {
                const { getMemoryService } = await import('./MemoryService');
                const memoryService = getMemoryService();
                const memoryResult = await memoryService.buildMemoryContext(userId, message);
                
                if (memoryResult.contextString) {
                    userMemoryContext = memoryResult.contextString;
                    console.log(`[ChatService] ğŸ’¾ ì‚¬ìš©ì ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ ì ìš©: ${memoryResult.memories.length}ê°œ ê¸°ì–µ, ${userMemoryContext.length}ì`);
                }
            } catch (e) {
                console.warn('[ChatService] MemoryService ë¡œë“œ ì‹¤íŒ¨:', e);
            }
        }
        
        // ğŸ†• 5. ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ìš”ì²­ì—ì„œ ì˜¨ ì´ë¯¸ì§€ + ë¬¸ì„œì—ì„œ ì¶”ì¶œëœ ì´ë¯¸ì§€)
        const allImages = [...(images || []), ...documentImages];
        let imageDescriptions: string[] = [];
        
        // ğŸ†• ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ë¹„ì „ ëª¨ë¸ë¡œ ë¶„ì„í•˜ì—¬ í…ìŠ¤íŠ¸ ì„¤ëª… ìƒì„±
        if (allImages.length > 0) {
            console.log(`[ChatService] ğŸ–¼ï¸ ${allImages.length}ê°œ ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘...`);
            
            onProgress?.({
                phase: 'selecting',
                message: `${allImages.length}ê°œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...`,
                progress: 2
            });
            
            for (let i = 0; i < Math.min(allImages.length, 3); i++) { // ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                try {
                    const analysisResponse = await this.client.chat(
                        [
                            { 
                                role: 'system', 
                                content: 'ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ 200ì ì´ë‚´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”. í…ìŠ¤íŠ¸, ë„í‘œ, ê·¸ë˜í”„ê°€ ìˆë‹¤ë©´ í•´ë‹¹ ë‚´ìš©ë„ í¬í•¨í•˜ì„¸ìš”.' 
                            },
                            {
                                role: 'user',
                                content: 'ì´ ì´ë¯¸ì§€ì˜ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”.',
                                images: [allImages[i]]
                            }
                        ],
                        { temperature: 0.2 }
                    );
                    
                    if (analysisResponse.content) {
                        imageDescriptions.push(analysisResponse.content.substring(0, 500));
                        console.log(`[ChatService] âœ… ì´ë¯¸ì§€ ${i + 1} ë¶„ì„ ì™„ë£Œ`);
                    }
                } catch (e) {
                    console.warn(`[ChatService] ì´ë¯¸ì§€ ${i + 1} ë¶„ì„ ì‹¤íŒ¨:`, e);
                    imageDescriptions.push(`[ì´ë¯¸ì§€ ${i + 1}: ë¶„ì„ ì‹¤íŒ¨]`);
                }
            }
        }

        // LLM í˜¸ì¶œ ë˜í¼ í•¨ìˆ˜
        const generateResponse = async (systemPrompt: string, userMessage: string): Promise<string> => {
            let response = '';
            const chatMessages = [
                { role: 'system', content: systemPrompt },
                { role: 'user', content: userMessage }
            ];

            await this.client.chat(chatMessages as any[], {}, (token) => {
                response += token;
            });

            return response;
        };

        // ğŸ†• í† ë¡  ì—”ì§„ ìƒì„± (ì™„ì „í•œ ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì ìš©)
        const discussionEngine = createDiscussionEngine(
            generateResponse,
            { 
                maxAgents: 5, 
                enableCrossReview: true,
                enableDeepThinking: true,
                
                // ğŸ†• ì»¨í…ìŠ¤íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í•„ë“œ ì „ë‹¬
                documentContext,
                conversationHistory,
                userMemoryContext,
                webSearchContext,
                
                // ğŸ†• ì´ë¯¸ì§€ ì»¨í…ìŠ¤íŠ¸ (ë¶„ì„ ê²°ê³¼ + ì›ë³¸ ë°ì´í„°)
                imageContexts: allImages,
                imageDescriptions,
                
                // ğŸ†• ì»¨í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„ ì„¤ì • (ì‚¬ìš©ì ë©”ëª¨ë¦¬ ìµœìš°ì„ )
                contextPriority: {
                    userMemory: 1,
                    conversationHistory: 2,
                    document: 3,
                    webSearch: 4,
                    image: 5
                },
                
                // ğŸ†• í† í° ì œí•œ ì„¤ì •
                tokenLimits: {
                    maxTotalTokens: 10000,  // í† ë¡  ëª¨ë“œëŠ” ë” ë§ì€ ì»¨í…ìŠ¤íŠ¸ í—ˆìš©
                    maxDocumentTokens: 4000,
                    maxHistoryTokens: 2000,
                    maxWebSearchTokens: 2000,
                    maxMemoryTokens: 1500,
                    maxImageDescriptionTokens: 500
                }
            },
            onProgress
        );

        // ì›¹ ê²€ìƒ‰ í•¨ìˆ˜ ë¡œë“œ (ì‚¬ì‹¤ ê²€ì¦ìš©)
        let webSearchFn: ((q: string, opts?: { maxResults?: number }) => Promise<WebSearchResult[]>) | undefined;
        try {
            const { performWebSearch } = await import('../mcp');
            webSearchFn = performWebSearch;
            console.log('[ChatService] ğŸ” ì›¹ ê²€ìƒ‰ ì‚¬ì‹¤ ê²€ì¦ í™œì„±í™”');
        } catch (e) {
            console.warn('[ChatService] ì›¹ ê²€ìƒ‰ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨, ì‚¬ì‹¤ ê²€ì¦ ë¹„í™œì„±í™”');
        }

        // í† ë¡  ì‹¤í–‰ (ì›¹ ê²€ìƒ‰ ì‚¬ì‹¤ ê²€ì¦ í¬í•¨)
        const result: DiscussionResult = await discussionEngine.startDiscussion(message, webSearchFn);

        // í† ë¡  ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì „ì†¡
        const formattedResponse = this.formatDiscussionResult(result);

        // í•œ ê¸€ìì”© ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
        for (const char of formattedResponse) {
            onToken(char);
        }

        // ğŸ†• ìƒì„¸ ë¡œê·¸
        console.log(`[ChatService] ğŸ¯ í† ë¡  ì™„ë£Œ: ${result.totalTime}ms, ì°¸ì—¬ì: ${result.participants.length}ëª…`);
        console.log(`[ChatService] ğŸ“Š ì»¨í…ìŠ¤íŠ¸ ì‚¬ìš© í˜„í™©:`);
        console.log(`   - ë¬¸ì„œ: ${documentContext ? 'âœ“' : 'âœ—'} (${documentContext.length}ì)`);
        console.log(`   - íˆìŠ¤í† ë¦¬: ${conversationHistory.length}ê°œ ë©”ì‹œì§€`);
        console.log(`   - ë©”ëª¨ë¦¬: ${userMemoryContext ? 'âœ“' : 'âœ—'} (${userMemoryContext.length}ì)`);
        console.log(`   - ì›¹ê²€ìƒ‰: ${webSearchContext ? 'âœ“' : 'âœ—'}`);
        console.log(`   - ì´ë¯¸ì§€: ${imageDescriptions.length}ê°œ ë¶„ì„ë¨`);

        return formattedResponse;
    }

    /**
     * ë‹¨ì¼ MCP ë„êµ¬ í˜¸ì¶œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
     * 
     * ğŸ†• ë“±ê¸‰ë³„ ê¶Œí•œ ê²€ì¦ ì ìš©:
     * - admin â†’ enterprise (ëª¨ë“  ë„êµ¬ í—ˆìš©)
     * - user â†’ ë“±ê¸‰ì— ë”°ë¼ ì œí•œ
     * - guest â†’ free (ê¸°ë³¸ ë„êµ¬ë§Œ)
     * 
     * ì§€ì› ë„êµ¬:
     * - web_search: ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
     * - web_fetch: ì›¹í˜ì´ì§€ ì½˜í…ì¸  ì¶”ì¶œ
     * - vision_ocr: ì´ë¯¸ì§€ OCR
     * - analyze_image: ì´ë¯¸ì§€ ë¶„ì„
     * - ê¸°íƒ€ MCP ê¸°ë³¸ ë„êµ¬
     * 
     * @param toolCall - ë„êµ¬ í˜¸ì¶œ ì •ë³´ (function.name, function.arguments)
     * @returns ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ ë¬¸ìì—´
     * @private
     */
    private async executeToolCall(toolCall: ToolCallInfo): Promise<string> {
        if (!toolCall.function || !toolCall.function.name) return 'Error: Invalid tool call';

        const toolName = toolCall.function.name;
        const toolArgs = toolCall.function.arguments;

        // ğŸ†• ë“±ê¸‰ë³„ ë„êµ¬ ì ‘ê·¼ ê¶Œí•œ ê²€ì¦
        if (this.currentUserContext) {
            const userTier = this.currentUserContext.tier;
            if (!canUseTool(userTier, toolName)) {
                const tierLabel = {
                    'free': 'ë¬´ë£Œ',
                    'pro': 'í”„ë¡œ',
                    'enterprise': 'ì—”í„°í”„ë¼ì´ì¦ˆ'
                }[userTier];
                
                console.warn(`[ChatService] âš ï¸ ë„êµ¬ ì ‘ê·¼ ê±°ë¶€: ${toolName} (tier: ${userTier})`);
                return `ğŸ”’ ê¶Œí•œ ì—†ìŒ: ${tierLabel} ë“±ê¸‰ì—ì„œëŠ” "${toolName}" ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—…ê·¸ë ˆì´ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤.`;
            }
        }

        console.log(`[ChatService] ğŸ”¨ Executing Tool: ${toolName} (tier: ${this.currentUserContext?.tier || 'unknown'})`, toolArgs);

        // ğŸŒ Ollama ë„¤ì´í‹°ë¸Œ ì›¹ ê²€ìƒ‰/ì¶”ì¶œ ë„êµ¬ ì²˜ë¦¬
        if (toolName === 'web_search') {
            try {
                const query = toolArgs.query as string;
                const maxResults = (toolArgs.max_results as number) || 5;
                const response = await this.client.webSearch(query, maxResults);

                if (response.results && response.results.length > 0) {
                    const formatted = response.results.map((r, i) =>
                        `[${i + 1}] ${r.title}\n    ${r.url}\n    ${r.content?.substring(0, 200) || ''}...`
                    ).join('\n\n');
                    return `ğŸ” ì›¹ ê²€ìƒ‰ ê²°ê³¼ (${response.results.length}ê°œ):\n\n${formatted}`;
                }
                return 'ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.';
            } catch (e: unknown) {
                const errorMessage = e instanceof Error ? e.message : String(e);
                console.error('[ChatService] web_search ì‹¤í–‰ ì‹¤íŒ¨:', errorMessage);
                return `Error: ${errorMessage}`;
            }
        }

        if (toolName === 'web_fetch') {
            try {
                const url = toolArgs.url as string;
                const response = await this.client.webFetch(url);

                if (response.content) {
                    return `ğŸ“¥ ì›¹í˜ì´ì§€: ${response.title}\n\n${response.content.substring(0, 3000)}`;
                }
                return 'í˜ì´ì§€ ì½˜í…ì¸ ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
            } catch (e: unknown) {
                const errorMessage = e instanceof Error ? e.message : String(e);
                console.error('[ChatService] web_fetch ì‹¤í–‰ ì‹¤íŒ¨:', errorMessage);
                return `Error: ${errorMessage}`;
            }
        }

        // ğŸ–¼ï¸ Vision OCR - ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if (toolName === 'vision_ocr') {
            try {
                const imagePath = toolArgs.image_path as string;
                const imageBase64 = toolArgs.image_base64 as string;
                const language = (toolArgs.language as string) || 'auto';

                let imageData: string;
                if (imageBase64) {
                    imageData = imageBase64;
                } else if (imagePath) {
                    // íŒŒì¼ì—ì„œ base64 ì¸ì½”ë”©
                    const fs = require('fs');
                    const path = require('path');
                    const absolutePath = path.resolve(imagePath);
                    const fileBuffer = fs.readFileSync(absolutePath);
                    imageData = fileBuffer.toString('base64');
                } else {
                    return 'Error: image_path ë˜ëŠ” image_base64ê°€ í•„ìš”í•©ë‹ˆë‹¤.';
                }

                console.log(`[ChatService] ğŸ” Vision OCR ì‹¤í–‰ ì¤‘...`);

                // Gemini Visionì„ í†µí•œ OCR
                const ocrResponse = await this.client.chat(
                    [
                        { role: 'system', content: 'You are an OCR expert. Extract ALL text from the image exactly as it appears. Preserve formatting, line breaks, and structure. If the text is in Korean, Japanese, or Chinese, output it in the original language.' },
                        {
                            role: 'user',
                            content: `ì´ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì›ë³¸ í˜•ì‹ì„ ìµœëŒ€í•œ ìœ ì§€í•˜ì„¸ìš”.${language !== 'auto' ? ` ì–¸ì–´: ${language}` : ''}`,
                            images: [imageData]
                        }
                    ],
                    { temperature: 0.1 }  // ë‚®ì€ temperatureë¡œ ì •í™•ë„ í–¥ìƒ
                );

                const extractedText = ocrResponse.content || '';
                console.log(`[ChatService] âœ… OCR ì™„ë£Œ: ${extractedText.length}ì ì¶”ì¶œ`);

                return `ğŸ“ OCR ê²°ê³¼:\n\n${extractedText}`;
            } catch (e: unknown) {
                const errorMessage = e instanceof Error ? e.message : String(e);
                console.error('[ChatService] vision_ocr ì‹¤í–‰ ì‹¤íŒ¨:', errorMessage);
                return `Error: ${errorMessage}`;
            }
        }

        // ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ - ì´ë¯¸ì§€ ë‚´ìš© ë¶„ì„ ë° ì„¤ëª…
        if (toolName === 'analyze_image') {
            try {
                const imagePath = toolArgs.image_path as string;
                const imageBase64 = toolArgs.image_base64 as string;
                const question = (toolArgs.question as string) || 'ì´ ì´ë¯¸ì§€ì— ë¬´ì—‡ì´ ìˆë‚˜ìš”? ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.';

                let imageData: string;
                if (imageBase64) {
                    imageData = imageBase64;
                } else if (imagePath) {
                    const fs = require('fs');
                    const path = require('path');
                    const absolutePath = path.resolve(imagePath);
                    const fileBuffer = fs.readFileSync(absolutePath);
                    imageData = fileBuffer.toString('base64');
                } else {
                    return 'Error: image_path ë˜ëŠ” image_base64ê°€ í•„ìš”í•©ë‹ˆë‹¤.';
                }

                console.log(`[ChatService] ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ì‹¤í–‰ ì¤‘...`);

                const analysisResponse = await this.client.chat(
                    [
                        { role: 'system', content: 'You are an expert image analyst. Describe images in detail, including objects, text, colors, composition, and any relevant context.' },
                        {
                            role: 'user',
                            content: question,
                            images: [imageData]
                        }
                    ],
                    { temperature: 0.3 }
                );

                const analysis = analysisResponse.content || '';
                console.log(`[ChatService] âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ`);

                return `ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:\n\n${analysis}`;
            } catch (e: unknown) {
                const errorMessage = e instanceof Error ? e.message : String(e);
                console.error('[ChatService] analyze_image ì‹¤í–‰ ì‹¤íŒ¨:', errorMessage);
                return `Error: ${errorMessage}`;
            }
        }

        // ê¸°ì¡´ MCP ë„êµ¬ ì‹¤í–‰
        const toolDef = builtInTools.find(t => t.tool.name === toolName);
        if (!toolDef) {
            return `Error: Tool '${toolName}' not found`;
        }

        try {
            const result = await toolDef.handler(toolArgs);
            if (result.isError) {
                return `Error executing properties: ${result.content.map(c => c.text).join('\n')}`;
            }
            return result.content.map(c => c.text).join('\n');
        } catch (e: unknown) {
            const errorMessage = e instanceof Error ? e.message : String(e);
            console.error(`[ChatService] Tool execution failed: ${errorMessage}`);
            return `Error: ${errorMessage}`;
        }
    }

    /**
     * í† ë¡  ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
     * 
     * í¬í•¨ ë‚´ìš©:
     * - í† ë¡  ìš”ì•½ í—¤ë”
     * - ì°¸ì—¬ ì „ë¬¸ê°€ë³„ ì˜ê²¬ (GPT ìŠ¤íƒ€ì¼ Thinking ë¸”ë¡ìœ¼ë¡œ ê¸°ë³¸ í¼ì¹¨)
     * - ìµœì¢… ì¢…í•© ë‹µë³€ (ì ‘í˜ ê°€ëŠ¥)
     * 
     * @param result - í† ë¡  ì—”ì§„ì˜ ê²°ê³¼ ê°ì²´
     * @returns ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ…ëœ ë¬¸ìì—´
     * @private
     */
    private formatDiscussionResult(result: DiscussionResult): string {
        let formatted = '';

        // í† ë¡  ìš”ì•½ í—¤ë”
        formatted += `## ğŸ¯ ë©€í‹° ì—ì´ì „íŠ¸ í† ë¡  ê²°ê³¼\n\n`;
        formatted += `> ${result.discussionSummary}\n\n`;
        formatted += `---\n\n`;

        // ğŸ†• ì°¸ì—¬ ì „ë¬¸ê°€ ì˜ê²¬ (GPT ìŠ¤íƒ€ì¼ ê¸°ë³¸ í¼ì¹¨ ìƒíƒœ)
        formatted += `## ğŸ“‹ ì „ë¬¸ê°€ë³„ ë¶„ì„\n\n`;

        for (const opinion of result.opinions) {
            // GPT ìŠ¤íƒ€ì¼ Thinking ë¸”ë¡
            formatted += `### ${opinion.agentEmoji} ${opinion.agentName}\n\n`;
            formatted += `> ğŸ’­ **Thinking**: ${opinion.agentName} ê´€ì ì—ì„œ ë¶„ì„ ì¤‘...\n\n`;
            formatted += `${opinion.opinion}\n\n`;
            formatted += `---\n\n`;
        }

        // ğŸ†• ìµœì¢… ì¢…í•© ë‹µë³€ (ì ‘í˜ ê°€ëŠ¥ - ì„ íƒì  í™•ì¸)
        formatted += `<details open>\n<summary>ğŸ’¡ <strong>ì¢…í•© ë‹µë³€</strong> (ì „ë¬¸ê°€ ì˜ê²¬ ì¢…í•©)</summary>\n\n`;
        formatted += result.finalAnswer;
        formatted += `\n\n</details>`;

        return formatted;
    }
}
