/**
 * ============================================================
 * OllamaClient - Ollama/Cloud LLM API í´ë¼ì´ì–¸íŠ¸
 * ============================================================
 * 
 * Ollama ë° Cloud LLM APIì™€ í†µì‹ í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ëª¨ë“ˆì…ë‹ˆë‹¤.
 * 
 * @module backend/core/ollama/client
 * @description
 * - í…ìŠ¤íŠ¸ ìƒì„± (generate) ë° ì±„íŒ… (chat) API ì§€ì›
 * - ìŠ¤íŠ¸ë¦¬ë° ë° ë…¼-ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
 * - Thinking ëª¨ë“œ, êµ¬ì¡°í™”ëœ ì¶œë ¥, ë„êµ¬ í˜¸ì¶œ ì§€ì›
 * - ì„ë² ë”© ìƒì„± (embed) ì§€ì›
 * - API í‚¤ ìë™ í´ë°± ë° ë¡œí…Œì´ì…˜
 * 
 * @requires axios - HTTP í´ë¼ì´ì–¸íŠ¸
 * @requires ./types - Ollama API íƒ€ì… ì •ì˜
 * @requires ./api-key-manager - API í‚¤ ê´€ë¦¬ì
 */

import axios, { AxiosInstance } from 'axios';
import {
    OllamaConfig,
    GenerateRequest,
    GenerateResponse,
    ChatRequest,
    ChatResponse,
    ChatMessage,
    ListModelsResponse,
    ModelOptions,
    ThinkOption,
    FormatOption,
    ToolDefinition,
    EmbedRequest,
    EmbedResponse
} from './types';
import { getConfig } from '../config';
import { createLogger } from '../utils/logger';
import { getApiKeyManager, ApiKeyManager } from './api-key-manager';

const logger = createLogger('OllamaClient');

const envConfig = getConfig();

/** ê¸°ë³¸ Ollama ì„¤ì • */
const DEFAULT_CONFIG: OllamaConfig = {
    baseUrl: envConfig.ollamaBaseUrl,
    model: envConfig.ollamaDefaultModel,
    timeout: envConfig.ollamaTimeout
};

/**
 * Ollama LLM í´ë¼ì´ì–¸íŠ¸ í´ë˜ìŠ¤
 * 
 * Ollama ë° Cloud LLM APIì™€ í†µì‹ í•˜ë©°, í…ìŠ¤íŠ¸ ìƒì„±, ì±„íŒ…,
 * ì„ë² ë”© ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
 * 
 * @class OllamaClient
 * @example
 * const client = new OllamaClient({ model: 'gemini-3-flash:cloud' });
 * const response = await client.generate('ì•ˆë…•í•˜ì„¸ìš”');
 * console.log(response);
 */
export class OllamaClient {
    /** Axios HTTP í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ */
    private client: AxiosInstance;
    /** í´ë¼ì´ì–¸íŠ¸ ì„¤ì • */
    private config: OllamaConfig;
    /** ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ (generate APIìš©) */
    private context: number[] = [];
    /** API í‚¤ ê´€ë¦¬ì */
    private apiKeyManager: ApiKeyManager;

    /**
     * OllamaClient ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     * 
     * @param config - í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì˜µì…˜
     * @param config.baseUrl - Ollama API ê¸°ë³¸ URL
     * @param config.model - ì‚¬ìš©í•  ê¸°ë³¸ ëª¨ë¸ëª…
     * @param config.timeout - ìš”ì²­ íƒ€ì„ì•„ì›ƒ (ms)
     */
    constructor(config: Partial<OllamaConfig> = {}) {
        this.config = { ...DEFAULT_CONFIG, ...config };
        this.apiKeyManager = getApiKeyManager();

        this.client = axios.create({
            baseURL: this.config.baseUrl,
            timeout: this.config.timeout,
            headers: {
                'Content-Type': 'application/json',
                ...this.apiKeyManager.getAuthHeaders()
            }
        });

        // ğŸ†• ìš”ì²­ ì¸í„°ì…‰í„°: ë™ì  API í‚¤ ì£¼ì…
        this.client.interceptors.request.use((config) => {
            const authHeaders = this.apiKeyManager.getAuthHeaders();
            if (authHeaders.Authorization) {
                config.headers.Authorization = authHeaders.Authorization;
            }
            return config;
        });

        // ğŸ†• ì‘ë‹µ ì¸í„°ì…‰í„°: ì‹¤íŒ¨ ì‹œ í´ë°± ì²˜ë¦¬
        this.client.interceptors.response.use(
            (response) => {
                this.apiKeyManager.reportSuccess();
                return response;
            },
            async (error) => {
                const switched = this.apiKeyManager.reportFailure(error);
                if (switched && error.config && !error.config._retry) {
                    error.config._retry = true;
                    error.config.headers.Authorization = this.apiKeyManager.getAuthHeaders().Authorization;
                    console.log('[OllamaClient] ğŸ”„ API í‚¤ ì „í™˜ í›„ ì¬ì‹œë„...');
                    return this.client.request(error.config);
                }
                throw error;
            }
        );
    }

    /**
     * í˜„ì¬ ì„¤ì •ëœ ëª¨ë¸ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
     * @returns í˜„ì¬ ëª¨ë¸ëª…
     */
    get model(): string {
        return this.config.model;
    }

    /**
     * ì‚¬ìš©í•  ëª¨ë¸ì„ ë³€ê²½í•©ë‹ˆë‹¤.
     * @param model - ìƒˆ ëª¨ë¸ëª…
     */
    setModel(model: string): void {
        this.config.model = model;
    }

    /**
     * ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
     * @returns ëª¨ë¸ ëª©ë¡ ì‘ë‹µ
     */
    async listModels(): Promise<ListModelsResponse> {
        const response = await this.client.get<ListModelsResponse>('/api/tags');
        return response.data;
    }

    /**
     * í…ìŠ¤íŠ¸ ìƒì„± APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
     * 
     * @param prompt - ì…ë ¥ í”„ë¡¬í”„íŠ¸
     * @param options - ëª¨ë¸ ì˜µì…˜ (temperature, top_p ë“±)
     * @param onToken - ìŠ¤íŠ¸ë¦¬ë° ì‹œ í† í°ë³„ ì½œë°± í•¨ìˆ˜
     * @param images - ì´ë¯¸ì§€ ë°ì´í„° ë°°ì—´ (Vision ëª¨ë¸ìš©, base64)
     * @returns ìƒì„±ëœ í…ìŠ¤íŠ¸ ì‘ë‹µ
     * 
     * @example
     * // ë…¼-ìŠ¤íŠ¸ë¦¬ë°
     * const response = await client.generate('Hello');
     * 
     * // ìŠ¤íŠ¸ë¦¬ë°
     * const response = await client.generate('Hello', {}, (token) => {
     *     process.stdout.write(token);
     * });
     */
    async generate(
        prompt: string,
        options?: ModelOptions,
        onToken?: (token: string) => void,
        images?: string[]
    ): Promise<string> {
        const request: GenerateRequest = {
            model: this.config.model,
            prompt,
            context: this.context,
            stream: !!onToken,
            options,
            images
        };

        if (onToken) {
            return this.streamGenerate(request, onToken);
        }

        const response = await this.client.post<GenerateResponse>('/api/generate', request);
        this.context = response.data.context || [];
        return response.data.response;
    }

    private async streamGenerate(
        request: GenerateRequest,
        onToken: (token: string) => void
    ): Promise<string> {
        const response = await this.client.post('/api/generate', request, {
            responseType: 'stream'
        });

        let fullResponse = '';
        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const data: GenerateResponse = JSON.parse(line);
                            if (data.response) {
                                fullResponse += data.response;
                                onToken(data.response);
                            }
                            if (data.done && data.context) {
                                this.context = data.context;
                            }
                        } catch (e) {
                            console.error('[OllamaClient] JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const data: GenerateResponse = JSON.parse(buffer);
                        if (data.response) {
                            fullResponse += data.response;
                            onToken(data.response);
                        }
                    } catch (e) {
                        // ğŸ”’ ìŠ¤íŠ¸ë¦¼ ëì˜ ë¶ˆì™„ì „í•œ JSONì€ ë””ë²„ê·¸ ë ˆë²¨ë¡œ ë¡œê¹…
                        logger.debug('[OllamaClient] Final buffer parse skipped (incomplete JSON)');
                    }
                }
                resolve(fullResponse);
            });
            response.data.on('error', reject);
        });
    }

    /**
     * í–¥ìƒëœ ì±„íŒ… APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
     * 
     * Thinking ëª¨ë“œ, êµ¬ì¡°í™”ëœ ì¶œë ¥, ë„êµ¬ í˜¸ì¶œì„ ì§€ì›í•©ë‹ˆë‹¤.
     * 
     * @param messages - ì±„íŒ… ë©”ì‹œì§€ ë°°ì—´ (system, user, assistant, tool)
     * @param options - ëª¨ë¸ ì˜µì…˜ (temperature, top_p ë“±)
     * @param onToken - ìŠ¤íŠ¸ë¦¬ë° ì‹œ í† í°ë³„ ì½œë°± (token, thinking?)
     * @param advancedOptions - ê³ ê¸‰ ì˜µì…˜
     * @param advancedOptions.think - Thinking ëª¨ë“œ (boolean | 'low' | 'medium' | 'high')
     * @param advancedOptions.format - ì¶œë ¥ í˜•ì‹ ('json' | JSON Schema)
     * @param advancedOptions.tools - ë„êµ¬ ì •ì˜ ë°°ì—´
     * @returns ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ë©”ì‹œì§€ (content, thinking?, tool_calls?)
     * 
     * @example
     * const response = await client.chat([
     *     { role: 'system', content: 'You are a helpful assistant.' },
     *     { role: 'user', content: 'Hello!' }
     * ], { temperature: 0.7 });
     */
    async chat(
        messages: ChatMessage[],
        options?: ModelOptions,
        onToken?: (token: string, thinking?: string) => void,
        advancedOptions?: {
            think?: ThinkOption;
            format?: FormatOption;
            tools?: ToolDefinition[];
        }
    ): Promise<ChatMessage> {
        const request: ChatRequest = {
            model: this.config.model,
            messages,
            stream: !!onToken,
            options,
            ...(advancedOptions?.think !== undefined && { think: advancedOptions.think }),
            ...(advancedOptions?.format && { format: advancedOptions.format }),
            ...(advancedOptions?.tools && { tools: advancedOptions.tools })
        };

        if (onToken) {
            return this.streamChat(request, onToken);
        }

        const response = await this.client.post<ChatResponse>('/api/chat', request);
        return response.data.message;
    }

    private async streamChat(
        request: ChatRequest,
        onToken: (token: string, thinking?: string) => void
    ): Promise<ChatMessage> {
        const response = await this.client.post('/api/chat', request, {
            responseType: 'stream'
        });

        let fullContent = '';
        let fullThinking = '';
        let toolCalls: any[] = [];

        return new Promise((resolve, reject) => {
            let buffer = '';

            response.data.on('data', (chunk: Buffer) => {
                logger.debug(`Data chunk received: ${chunk.length} bytes`);
                buffer += chunk.toString();
                const lines = buffer.split('\n');
                buffer = lines.pop() || '';

                for (const line of lines) {
                    if (line.trim()) {
                        try {
                            const data: ChatResponse = JSON.parse(line);

                            // Handle thinking trace
                            if (data.message?.thinking) {
                                fullThinking += data.message.thinking;
                                onToken('', data.message.thinking);
                            }

                            // Handle content
                            if (data.message?.content) {
                                fullContent += data.message.content;
                                onToken(data.message.content);
                            }

                            // Handle tool calls
                            if (data.message?.tool_calls) {
                                toolCalls = data.message.tool_calls;
                            }
                        } catch (e) {
                            console.error('[OllamaClient] Chat JSON Parse Error:', e);
                        }
                    }
                }
            });

            response.data.on('end', () => {
                if (buffer.trim()) {
                    try {
                        const data: ChatResponse = JSON.parse(buffer);
                        if (data.message?.thinking) {
                            fullThinking += data.message.thinking;
                        }
                        if (data.message?.content) {
                            fullContent += data.message.content;
                            onToken(data.message.content);
                        }
                        if (data.message?.tool_calls) {
                            toolCalls = data.message.tool_calls;
                        }
                    } catch (e) {
                        // ğŸ”’ ìŠ¤íŠ¸ë¦¼ ëì˜ ë¶ˆì™„ì „í•œ JSONì€ ë””ë²„ê·¸ ë ˆë²¨ë¡œ ë¡œê¹…
                        logger.debug('[OllamaClient] Chat final buffer parse skipped (incomplete JSON)');
                    }
                }

                const result: ChatMessage = {
                    role: 'assistant',
                    content: fullContent
                };

                if (fullThinking) {
                    result.thinking = fullThinking;
                }

                if (toolCalls.length > 0) {
                    result.tool_calls = toolCalls;
                }

                resolve(result);
            });
            response.data.on('error', reject);
        });
    }

    /**
     * í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
     * 
     * ì˜ë¯¸ë¡ ì  ê²€ìƒ‰, ìœ ì‚¬ë„ ë¹„êµ ë“±ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
     * 
     * @param input - ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë˜ëŠ” í…ìŠ¤íŠ¸ ë°°ì—´
     * @param model - ì„ë² ë”© ëª¨ë¸ëª… (ê¸°ë³¸ê°’: 'embeddinggemma')
     * @returns ì„ë² ë”© ë²¡í„° ë°°ì—´
     * 
     * @example
     * const embeddings = await client.embed('Hello world');
     * console.log(embeddings[0].length); // ë²¡í„° ì°¨ì› ìˆ˜
     */
    async embed(input: string | string[], model?: string): Promise<number[][]> {
        const request: EmbedRequest = {
            model: model || 'embeddinggemma',
            input
        };

        const response = await this.client.post<EmbedResponse>('/api/embed', request);
        return response.data.embeddings;
    }

    /**
     * Ollama ì„œë²„ì˜ ê°€ìš©ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤.
     * @returns ì„œë²„ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
     */
    async isAvailable(): Promise<boolean> {
        try {
            await this.client.get('/');
            return true;
        } catch {
            return false;
        }
    }

    /**
     * ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
     * ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ ì‹œì‘í•  ë•Œ í˜¸ì¶œí•©ë‹ˆë‹¤.
     */
    clearContext(): void {
        this.context = [];
    }
}

/**
 * OllamaClient ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í•¨ìˆ˜ì…ë‹ˆë‹¤.
 * 
 * @param config - í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì˜µì…˜
 * @returns ìƒˆ OllamaClient ì¸ìŠ¤í„´ìŠ¤
 * 
 * @example
 * const client = createClient({ model: 'gemini-3-flash:cloud' });
 */
export const createClient = (config?: Partial<OllamaConfig>): OllamaClient => {
    return new OllamaClient(config);
};
